{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Probabilistic programming\n",
        "---"
      ],
      "id": "e58d9eb1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import pymc as pm\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import arviz as az\n",
        "from IPython.display import display, Markdown\n",
        "az.style.use('arviz-darkgrid')\n",
        "np.random.seed(44)\n",
        "import seaborn as sns"
      ],
      "id": "f0c171e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "plt.rcParams['font.size'] = 15\n",
        "plt.rcParams['legend.fontsize'] = 'medium'\n",
        "plt.rcParams.update({\n",
        "    \"figure.figsize\": [12.0, 5.0],\n",
        "    'figure.facecolor': '#fffff8',\n",
        "    'axes.facecolor': '#fffff8',\n",
        "    'figure.constrained_layout.use': True,\n",
        "    'font.size': 14.0,\n",
        "    'hist.bins': 'auto',\n",
        "    'lines.linewidth': 3.0,\n",
        "    'lines.markeredgewidth': 2.0,\n",
        "    'lines.markerfacecolor': 'none',\n",
        "    'lines.markersize': 8.0, \n",
        "})\n",
        "sns.set(rc={'figure.figsize':(7,3)})"
      ],
      "id": "0bd2c533",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Giorgio Corani <br/>\n",
        "*Bayesian Data Analysis and Probabilistic Programming*\n",
        "<br/>\n",
        "<br/>\n",
        "``giorgio.corani@supsi.ch``\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Probabilistic programming\n",
        "\n",
        "\n",
        "* If prior and likelihood are not conjugate  the posterior is  untractable, in which case it has to be numerically sampled. Designing an appropriate sampling algorithm requires much expertise.\n",
        "\n",
        "\n",
        "* Languages for *probabilistic programming* address this problem.\n",
        "\n",
        "\n",
        "* They describe a probabilistic model in  few lines and  compute the posterior of the parameters (*inference*) automatically. \n",
        "\n",
        "# Probabilistic programming languages\n",
        "\n",
        "\n",
        "* We  use PyMC, a package for probabilistic programming under Python.\n",
        "\n",
        "* We will  also the arviz package, which provides functions to analyze the posterior. \n",
        "    \n",
        "\n",
        "* Another  language for probabilistic programming is [Stan](https://mc-stan.org/).  This can be used to implement a custom model, or via the R packages ( [brms](https://cran.r-project.org/web/packages/brms/index.html) and  [rstanarm](https://mc-stan.org/rstanarm/))  which provide some pre-implemented models.\n",
        "\n",
        "# Estimating the bias $\\theta$ of the coin\n",
        "\n",
        "\n",
        "* We start by generating   data with a known $\\theta$ so that we can check the accuracy of our estimate.\n"
      ],
      "id": "09790d1a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#Generating the data\n",
        "np.random.seed(123)\n",
        "n_draws = 100\n",
        "theta_real = .35  \n",
        "\n",
        "#we generate the data (rvs stands for random-variates)\n",
        "data = stats.bernoulli.rvs(p=theta_real, size=n_draws)\n",
        "\n",
        "# the data are  a vector of 0 and 1; with this seed they contain 30 successes.\n",
        "print(data)\n",
        "print(sum(data))"
      ],
      "id": "50a6962b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The beta-binomial model\n",
        "\n",
        "* We consider  a flat prior for $\\theta$:  Beta(1,1). \n",
        "\n",
        "* $y$ is the number of observed heads while $n$ is the number of draws.\n",
        "\n",
        "* The likelihood is binomial:\n",
        "    * $\\operatorname{Bin}(y, p, n)$ is the probability of observing $y$ successes in $n$ independent trials, each with probability $p$.\n",
        "\n",
        "\\begin{align}\n",
        "\\theta &\\sim \\operatorname{Beta}(\\alpha=1, \\beta=1)\\\\\n",
        "y &\\sim \\operatorname{Bin}(n=n_{\\text{draws}}\n",
        ", p=\\theta)\n",
        "\\end{align}\n",
        "\n",
        "# The beta-binomial model\n",
        "\n",
        "We can also consider an equivalent but slightly different parameterization:\n",
        "\n",
        "\\begin{align}\n",
        "\\theta &\\sim \\operatorname{Beta}(\\alpha=1, \\beta=1)\\\\\n",
        "y_i &\\sim \\operatorname{Bernoulli}(\\theta)\n",
        "\\end{align}\n",
        "\n",
        "where $y_i$ denotes the outcome (0,1) of the i-th draw. In this case the data are a vector of 0s and 1s.\n"
      ],
      "id": "676a8c14"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Beta-binomial model in Pymc\n",
        "beta_binomial_model = pm.Model()\n",
        "\n",
        "# The lines within the \"with\" statement refer to the same model \n",
        "with beta_binomial_model:\n",
        "    #The first argument is  a string specifying the name of the random variable, which should\n",
        "    #match the name of the Python variable.\n",
        "\n",
        "    #Uniform prior, i.e., Beta(1,1) \n",
        "    theta = pm.Beta('theta', alpha=1, beta=1)  \n",
        "    \n",
        "    #Likelihood, characterized by the keyword  `observed`.\n",
        "    #y = pm.Bernoulli('y', p=theta, observed=data)  # likelihood (one Bernoulli trial at a time)\n",
        "    y = pm.Binomial('y',n=n_draws, p=theta, observed=sum(data)) # likelihood (y successes within n_draws experiments)"
      ],
      "id": "53921921",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with beta_binomial_model:\n",
        "    trace = pm.sample()"
      ],
      "id": "131ddcfb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference\n",
        "\n",
        "\n",
        "*  Sampling from the posterior  is called *inference*. \n",
        "\n",
        "\n",
        "* We make  inference about the parameters, i.e., the unobserved variables to which we assigned a prior.\n",
        "\n",
        "\n",
        "* In this case we make inference about $\\theta$.\n",
        "\n",
        "## Plotting the posterior with Arviz\n",
        "\n",
        "* ArviZ is a Python package which analyzes the PyMC\n",
        "   trace.\n",
        "\n",
        "\n",
        "* We evaluate  the sampled posterior through ArviZ's `plot_trace` function.\n",
        "\n",
        "\n",
        "* The `trace` contains  the sampled values of the unobserved variables, called *parameters*. In this case,  $\\theta$ is the only parameter.\n"
      ],
      "id": "32e21b4f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# We get two plots for theta:\n",
        "# - on the  left a density plot (KDE, Kernel Density Estimation). The different lines refer to different MCMC chains run in parallel.\n",
        "# - on the right the trace (the values sampled at each step). Also here the trace of different chains is shown (light blue vs dark blue)\n",
        "\n",
        "# We can also see  the chains mix well  and that the density plot are smooth and overlap.\n",
        "\n",
        "#the plot_trace function allows to visually check the quality of the sampling: \n",
        "#do the different chains providing a similar histogram?\n",
        "# does the chain behave almost as white noise?\n",
        "#is the histogram smooth?\n",
        "\n",
        "\n",
        "import arviz as az\n",
        "az.plot_trace(trace);"
      ],
      "id": "cb7626a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "az.summary(trace)"
      ],
      "id": "8114c057",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# the plot_posterior function is more concerned with the estimated values, it reports point estimate and HDI\n",
        "# the posterior mean, computed analytically, is (1 + 30)/ (1 + 30 + 70 +1) = 0.303, almost identical to the value estimated by pymc3.\n",
        "#The true theta which generates the data  is 0.35, which is well within the HDI.\n",
        "az.plot_posterior(trace);"
      ],
      "id": "2f0fb979",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diagnosing  the chains \n",
        "\n",
        "<img src='img/trace-burn.png' width=400 align=\"center\" >\n",
        "\n",
        "* The values in the chain must be *representative* of the posterior distribution. \n",
        "* They should not be  influenced by the arbitrary initial value of the chain.\n",
        " > This figure and the following ones are from Krushke (Chap 7.5)\n",
        "\n",
        "# Diagnosing  the chains\n",
        "\n",
        "<img src='img/trace-burn.png' width=400 align=\"center\" >\n",
        "\n",
        "* It takes a few hundred steps for the three chains to converge to the same region of the parameter\n",
        "\n",
        "\n",
        "* The first several hundred steps (*burn-in*) of the chain should be discarded as they are not representative.\n",
        "\n",
        "# Removing the burn-in period\n",
        "<img src=\"img/trace-convergence.png\" width=500 >\n",
        "\n",
        "* PyMC3 automatically removes the burn-in period.\n",
        "* Once removed the burn-in period,   the three chains meander  smoothly and overlap each other (*good mixing*).\n",
        "* The trace should look like white noise.\n",
        "\n",
        "\n",
        "# Checking the  density plots\n",
        "\n",
        "\n",
        "<img src='img/kde-no-convergence.png' width=500 >\n",
        "\n",
        "* We compute a density plot on the samples from each chain.\n",
        "\n",
        "* The density plots of the three chains do not overlap  well during the burn-in period: the chains have not converged.\n",
        "\n",
        "# Density plots which overlap well \n",
        "\n",
        "\n",
        "<img src='img/kde-convergence.png' width=500 >\n",
        "\n",
        "* This suggests that the chains contain representative values from the posterior distribution. \n",
        "* The HDI limits are slightly different for each chain because each chain is a finite random sample. \n",
        "\n",
        "# Poor mixing\n",
        "<img src='img/chain-poor-mixing.png' width=500 style=\"display=block; margin:auto\"/>\n",
        "\n",
        "* The blue chain got stuck: it is a horizontal line for long number of samples.\n",
        "* This is a problem: the sampler is only accepting  proposals in the very close neighborhood.\n",
        "* It is thus sampling very slowly;  in  finite samples this prevents sampling the entire posterior,  biasing  the results.\n",
        "\n",
        "# Effective sample size (ESS)\n",
        "\n",
        "* The chains might be auto-correlated, i.e.,  the value samples at the current iteration is similar to the value sampled in the previous iteration.\n",
        "\n",
        "* How much independent information is in the chains ?\n",
        "\n",
        "* What would be the sample size of a completely non-autocorrelated chain that yielded the same information?\n",
        "\n",
        "* The ESS estimates how many independent draws contain the same amount of information as the dependent sample obtained by MCMC sampling.\n",
        "\n",
        "# ESS with high auto-correlation\n",
        "\n",
        "<img src='img/ess-low.png' width=1000 >\n",
        "\n",
        "# ESS with low auto-correlation\n",
        "\n",
        "<img src='img/ess-high.png' width=1000 align=\"center\" >\n",
        "\n",
        "# Effective sample size (ESS)\n",
        "\n",
        "*  The effective sample size divides the actual sample size by the amount of autocorrelation in the chain.\n",
        "\n",
        "\\begin{align}\n",
        "\\text{ESS}= \\frac{N}{(1 + 2\\sum_{k=1}^{k=\\infty} ACF(k))}\n",
        "\\end{align}\n",
        "\n",
        "where\n",
        "$$\n",
        "ACF(k)  = \\operatorname{Cor}(\\theta_t, \\theta_{t+k})\n",
        "$$\n",
        "\n",
        "# Bulk and Tail Effective Sample Size\n",
        "\n",
        "* The *Bulk Effective Sample Size* (ess_bulk) is a useful measure for sampling efficiency in the bulk of the distribution (related e.g. to efficiency of mean and median estimates).\n",
        "\n",
        "* The *Tail Effective Sample Size* (ess_tail) estimates  the effective sample sizes for 5% and 95% quantiles; it is thus a useful measure of sampling efficiency in the tails of the distribution \n",
        "\n",
        "* Both  should be at least  (approximately) 400,  in order to have be reliable  estimates of the related posterior quantiles. \n",
        "\n",
        "# A further diagnostic: Rhat\n",
        "\n",
        "* If the chains have converged,  they should be very similar to one another; if not, one or more of the chains has failed to converge.\n",
        "\n",
        "* Rhat thus compares the variance between chains with the variance within chains.  Ideally, Rhat = 1.\n",
        "\n",
        "* It is ok if Rhat < 1.1; higher values signal a lack of convergence.\n",
        "\n",
        "<img src='img/rhat-example.png' width=500 align=\"center\" >\n",
        "\n",
        "# Summarizing the posterior\n",
        "\n",
        "The `az.summary` function show different information about  $\\theta$:\n",
        "\n",
        "\n",
        "* the mean, the standard deviation and the  HDI (whose desired coverage can be set via 'hdi_prob') \n",
        "\n",
        "\n",
        "* the effective number of samples for bulk and tail\n",
        "\n",
        "\n",
        "* Rhat\n"
      ],
      "id": "c8e82ae4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#the actual theta is 0.35\n",
        "#recall our prior is Beta(1,1); we have 30 successes in 100 trials.\n",
        "#the posterior mean  is analytically (1+30)/(2+100)=0.303\n",
        "#this is indeed very close to the posterior mean of our samples\n",
        "\n",
        "#This is relatively far from 0.35, but the actual value is included in the 95% HDI.\n",
        "#That is why HDI is more meaningful than a point estimate.\n",
        "\n",
        "# The posterior  is well sampled:  rhat is 1,  both ess are high.\n",
        "az.summary(trace, hdi_prob=0.95)"
      ],
      "id": "8affa8f5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Your turn\n",
        "\n",
        "* Replace the beta distribution with a uniform one in the interval [0,1] and compare the results.\n",
        "\n",
        "\n",
        "* Replace the beta distribution with a uniform one in the interval [0, 0.2] and compare the results.\n",
        "\n",
        "Link to the documentation of the Uniform distributon in pymc: https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.Uniform.html\n",
        "\n",
        "  \n",
        "\n",
        "# Reporting the posterior \n",
        "\n",
        "The `plot_posterior` function provides a visual summary of the posterior:\n",
        "\n",
        "*  the density plot\n",
        "\n",
        "\n",
        "* the mean of the distribution (we can have  the median or mode using the `point_estimate` argument; with asymmetric distribustions, the mode is more meaningful.) \n",
        "\n",
        "\n",
        "* the 95% HPD, whose coverage can be set the `alpha` argument. \n"
      ],
      "id": "1b7b92e3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "az.plot_posterior (trace, hdi_prob = 0.95);"
      ],
      "id": "7f399214",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Decisions based on posterior\n",
        "\n",
        "* Assume  we have to decide whether or not the coin is biased, i.e., if it lands heads with probability different from 0.5. \n",
        "\n",
        "\n",
        "\n",
        "* We thus check whether the reference value 0.5 is within  the HDI interval. \n",
        "\n",
        "\n",
        "\n",
        "* The 95% HDI does not contain 0.5 and it rules out  the hypothesis of the coin being unbiased. The plausible values of $\\theta$ are roughly between 0.22 and 0.39.\n"
      ],
      "id": "a8e424e8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# the specific reference value (0.5) in this case rejected as it does not belong to the HDI.\n",
        "az.plot_posterior(trace, ref_val=0.5);"
      ],
      "id": "383cc66c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Region of Practical Equivalence (ROPE)\n",
        "\n",
        "* The probability of  *exactly*  $\\theta$=0.5 is zero, since $\\theta$ is a continous variables (we integrate the pdf over an interval in order to obtain a probability).\n",
        "\n",
        "\n",
        "*  Generally we do not need such sharp assesments; rather,  we need  the probability of $\\theta$ being in a small interval around 0.5, which means that the coin is  *practically* unbiased.\n",
        "\n",
        "\n",
        "* Such interval is the   _region of practical equivalence_  (ROPE). \n",
        "\n",
        "# ROPE \n",
        "\n",
        "> A ROPE is an arbitrary interval that is determined using prior and relevant knowledge about a topic. Any value within this range is considered equivalent.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "* For instance we might  consider that   $\\theta$  between 0.49 and 0.51 is a   *practically* unbiased coin. \n",
        "\n",
        "\n",
        "# Making decision with the ROPE\n",
        "\n",
        "Let us assume to ROPE to be the interval  [0.49, 0.51]\n",
        "\n",
        "\n",
        "* The hypothesis of practical equivalence  is  *rejected*  if the  ROPE contains low probability (e.g., < 5%), as in the following example.\n"
      ],
      "id": "eabe74d5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# We show both the 95% HDI and the rope. \n",
        "#We reject the hypothesis of the coin being practically unbiased.\n",
        "\n",
        "az.plot_posterior (trace, rope = [0.49, 0.51]);"
      ],
      "id": "62f36a81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Making decision with the ROPE\n",
        " \n",
        "\n",
        "## Verifiying the hypothesis of practical equivalence\n",
        "\n",
        "* Set a significance level $\\alpha$; typically, $\\alpha$ =0.05.\n",
        "\n",
        "* A  hypothesis of practical equivalence is  *accepted* if the parameter is contained within the ROPE  with  probability $\\textgreater$ $1-\\alpha$ (e.g., >95%).\n",
        "\n",
        "* A  hypothesis of practical equivalence is  *rejected* if the parameter is contained within the ROPE  with  probability $\\textless$ $\\alpha$ (e.g., <5%).\n",
        "\n",
        "\n",
        "* Otherwise, we  cannot reach a strong conclusion, and we might collect furher data. Anyway, the posterior probability of the parameter beloning to the ROPE or lying outside the ROPE is often already helpful for making decisions.\n",
        "\n",
        "\n",
        "\n",
        "# Your turn: compare classifiers\n",
        "\n",
        "* In a certain classification problem, a baseline classifier has accuracy 90%.\n",
        "\n",
        "\n",
        "* It only makes sense putting in operation a novel classifier if it improves the accuracy of at least 2 points. Hence algorithms with accuracy lower than 92% are not interesting.\n",
        "\n",
        "\n",
        "* In  a preliminary test, the novel classifier correctly predicts 48 instances out of 50.\n",
        "\n",
        "\n",
        "* Which is your conclusion?\n",
        "    *  Hint: computer  the probability of improving accuracy by more than 2 points compared to the current classifier. \n",
        "\n",
        "\n",
        "* Repeat the analysis for the case in which the novel classifier has correctly prediction 95 instances out of 100.\n",
        "\n",
        "# Solutions\n",
        "\n",
        "# Solution:  beta-binomial model with uniform prior\n"
      ],
      "id": "f130ed15"
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Beta-binomial model with uniform prior in 0,1\n",
        "unif_range01_model = pm.Model()\n",
        "\n",
        "\n",
        "with unif_range01_model:\n",
        "    #Uniform prior an on open interval\n",
        "    theta = pm.Uniform('theta', lower= 0.001, upper= 0.999)  \n",
        "    y = pm.Binomial('y',n=n_draws, p=theta, observed=sum(data))\n",
        "    unif_trace = pm.sample()"
      ],
      "id": "bcaf12a2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# equivalent to the result obtained with the beta prior; any small difference is due to sampling uncertainty\n",
        "az.summary(unif_trace)"
      ],
      "id": "b4bd2a63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solution:  beta-binomial model with truncated prior\n"
      ],
      "id": "6e7c9a8a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Beta-binomial model with uniform prior in 0, 0.2\n",
        "unif_0_02_model = pm.Model()\n",
        "\n",
        "with unif_0_02_model:\n",
        "    theta = pm.Uniform('theta', lower= 0.001, upper= 0.02)  \n",
        "    y = pm.Binomial('y',n=n_draws, p=theta, observed=sum(data))\n",
        "    trace_0_02 = pm.sample()"
      ],
      "id": "e757256e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#in this case we have the posterior truncated in 0.02, due to a wrong choice of the prior\n",
        "az.summary(trace_0_02)"
      ],
      "id": "43aa5795",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solution: assess the accuracy of the new classifier\n"
      ],
      "id": "c63db075"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Here we use a non-informative Beta(1,1) prior\n",
        "experiments = 50\n",
        "n_correct = 48\n",
        "\n",
        "# The lines within the \"with\" statement refer to the same model \n",
        "with pm.Model() as beta_binomial_classifier:\n",
        "    #Uniform prior, i.e., Beta(1,1). This prior might serve as a baseline, but it is not realistic.. we know that \n",
        "    #the accuracy of the novel classifier will be around 0.9, +- something\n",
        "    theta = pm.Beta('theta', alpha=1, beta=1)  \n",
        "    y = pm.Binomial('y',n=experiments, p=theta, observed=n_correct) # likelihood (y successes within n_draws experiments)\n",
        "    trace_classifier = pm.sample(return_inferencedata=True)\n"
      ],
      "id": "9121dd4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# according to the our analysis, there is about 78% probability that your classifier constitutes an actual improvement\n",
        "az.plot_posterior(trace_classifier, rope=[0.90,0.92], ref_val=0.92 );"
      ],
      "id": "b48dbb1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#actually we can use a more sensible prior. We can expect the performance of our classifier to be about 90%. \n",
        "#To tune the prior, we check the 95% HDI  obtained under different choices of a and b.\n",
        "from scipy.stats import beta\n",
        "\n",
        "for (a,b) in [(9,1), (18,2)]:\n",
        "    print(a,b)\n",
        "    current_var = stats.beta(a=a, b=b)\n",
        "    interval = current_var.interval(0.95)\n",
        "    print( np. round ( interval, 2))"
      ],
      "id": "dbd2dc94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# we now set the prior as beta(18,2)\n",
        "with pm.Model() as beta_binomial_prior2:\n",
        "    theta = pm.Beta('theta', alpha=18, beta=2)  \n",
        "    y = pm.Binomial('y',n=experiments, p=theta, observed=n_correct) # likelihood (y successes within n_draws experiments)\n",
        "    trace_classifier = pm.sample(return_inferencedata=True)\n",
        "    az.plot_posterior(trace_classifier, rope=[0.90,0.92], ref_val=0.92);"
      ],
      "id": "5a53e64c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "#There is 18% probability of the novel classifier  being indeed practically better than the current one.\n",
        "#There is 82% probability of the novel classifier  being  practically equivalent to the current one.\n",
        "#This is good evidence for the novel classifier, but it might be worth collecting even more data.\n",
        "az.plot_posterior(trace_classifier, rope=[0.90,0.92], ref_val=0.92);"
      ],
      "id": "0d7b23db",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}