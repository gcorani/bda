---
title: "The beta-binomial model"
author: "Giorgio Corani  - (IDSIA, SUPSI)"
date: 'Bayesian Data Analysis and Probabilistic Programming'
output:
  beamer_presentation:
    latex_engine: xelatex
    fig_width: 7
    fig_height: 3.5
    highlight: tango
    theme: metropolis
    includes:
      in_header: header.tex
  slidy_presentation:
    highlight: tango
  ioslides_presentation:
    highlight: tango
fontsize: 13pt
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
library(reticulate)
use_condaenv(condaenv = "/Users/giorgio/opt/anaconda3/envs/pymc_env")
#necessary to run pymc
reticulate::py_run_string("import pymc as mc")
```


```{python, echo=FALSE}
import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy.stats import beta 
from matplotlib import pyplot as plt
import seaborn as sns
sns.set_theme()
plt.rcParams.update({
    "text.usetex": True,
    "font.family": "sans-serif",
    "font.sans-serif": ["Helvetica"]})
```


```{r, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```



```{python}
#necessary to run pymc
import pymc as pm
```

# The bias $\theta$ of a coin

-   A coin falls heads with probability $\theta \in (0,1)$ \bigskip

-   $\theta$ is the *bias* of the coin

    -   $\theta$ =0: it always lands tails
    -   $\theta$ =1: it always lands heads \bigskip

-   $\theta \in (0,1)$ is a continuous parameter


```{python, echo=FALSE, fig.height=2, fig.align="center"}
plt.figure(figsize=(10, 3))
x = np.linspace(0, 1, 100)

for ind, (a, b) in enumerate([(1, 1)]):
    y = stats.beta.pdf(x, a, b)
    #plt.subplot(1, 3, ind+1)
    plt.plot(x, y, label='a = %s\nb = %s' % (a, b))
    plt.legend(fontsize=12)
```


```{python}
import pymc as pm
import numpy as np
import scipy.stats as stats
import pandas as pd
import matplotlib.pyplot as plt
import arviz as az
from scipy.stats import t
from scipy.stats import norm
import seaborn as sns
az.style.use('arviz-darkgrid')
np.random.seed(44)
```

```{python}
#Below  the  66 measurements.

data = np.array([248.28, 248.26, 248.33, 248.24, 248.34, 247.56, 248.27, 248.16,
                  248.4, 247.98, 248.29, 248.22, 248.24, 248.21, 248.25, 248.3,
                  248.23, 248.29, 248.31, 248.19, 248.24, 248.2, 248.36, 248.32,
                  248.36, 248.28, 248.25, 248.21, 248.28, 248.29, 248.37, 248.25,
                  248.28, 248.26, 248.3, 248.32, 248.36, 248.26, 248.3, 248.22,
                  248.36, 248.23, 248.27, 248.27, 248.28, 248.27, 248.31, 248.27,
                  248.26, 248.33, 248.26, 248.32, 248.32, 248.24, 248.39, 248.28,
                  248.24, 248.25, 248.32, 248.25, 248.29, 248.27, 248.28, 248.29,
                  248.16, 248.23])
```


# the model
```{python}
# Implementation with  informative priors 

with pm.Model() as normal_model:
    # Based on prior information, the mean travel time should be within  (120,  360).
    # This information can be represented by a normal distribution with mu = 240, sigma = 60.
    mu = pm.Normal('mu', 240, 60)
    
    # By using a  scale parameter of 3, the median  of the halfnormal is close to 2., 
    sigma = pm.HalfNormal('sigma', 3)

    
    #likelihood. The observation are stored in vector 'data'.
    #and assumed to be independent.
    y = pm.Normal('y', mu=mu, sigma=sigma, observed=data)
    
    trace_normal = pm.sample()
```


# Showing the posterior

```{python}
with  normal_model:
    az.plot_trace(trace_normal);
```



