---
title: "The normal-normal model"
author: "Giorgio Corani"
date: 'Bayesian Data Analysis and Probabilistic Programming'
output:
  beamer_presentation:
    latex_engine: xelatex
    fig_width: 7
    fig_height: 3.5
    highlight: tango
    theme: metropolis
    includes:
      in_header: header.tex
  slidy_presentation:
    highlight: tango
  ioslides_presentation:
    highlight: tango
fontsize: 13pt
---

```{r setup, include=FALSE}
library(reticulate)
```

```{python, echo=FALSE}
import numpy as np
import pandas as pd
import arviz as az
import scipy.stats as stats
from matplotlib import pyplot as plt
from scipy.stats import norm
from scipy.stats import halfnorm
import seaborn as sns
sns.set_theme()
plt.rcParams.update({
    "text.usetex": True,
    "font.family": "sans-serif",
    "font.sans-serif": ["Helvetica"]})
az.style.use('arviz-darkgrid')
```

# Credits

* Chap. 5 of *Bayes Rules! An Introduction to Applied Bayesian Modeling*
  * https://www.bayesrulesbook.com/chapter-5.html



# The Normal model

* Let $Y$  be a continuous random variable which can take  values in (−$\infty$,$\infty$)  

\bigskip

* The variability of Y might be well represented by a Normal model 
 $$Y ∼ N(\mu,\sigma^2)$$


# The Normal model

* The Normal pdf is 

$$ f(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg[{-\frac{(y-\mu)^2}{2\sigma^2}}\bigg] $$

\bigskip

* With:

\begin{align*}
E(Y) &= Mode(Y)=μ \\
Var(Y) &= \sigma^2 \\
SD(Y) &= \sigma
\end{align*}

# Standard deviation $\sigma$

* $\sigma$ provides a sense of scale for $Y$. 

\bigskip

* Roughly 95% of $Y$ values are within 2 standard deviations of $\mu$:
$$\mu \pm 2 \sigma$$

\bigskip 

* Roughly 99% of $Y$ values are within 3 standard deviations of $\mu$:
$$\mu \pm 3 \sigma$$

# The normal model

* The Normal model is bell-shaped and symmetric around $\mu$. 

\bigskip

* As σ gets larger, the pdf becomes more spread out.

\bigskip
* Though a Normal variable is defined in (−∞, ∞), the   plausibility of values that are more than 3 standard deviations σ from the mean $\mu$ is negligible.

```{r figurename, echo=FALSE, out.width = '75%'}
knitr::include_graphics("normal-tuning.png")
```

# Example


* The  volume (in cubic centimeters) the hippocampus (a part of the brain)  is often researched in studies about the effect of concussions.

\bigskip

* In the general population, both halves of the hippocampus have a volume between 3.0 and 3.5 cubic centimeters.

\bigskip

* Thus, the  hippocampal volume is thought to vary, within the population,  between 6 and 7 cm$^3$.

\bigskip

* The average volume $\mu$ is thought to be between 6.4  and 6.6 cm$^3$.


# Prior

* Assuming a symmetric distribution, we can formalize our  prior information about $\mu$ as:

\begin{align*}
\mu & \sim N(6.5, 0.05)\\
\mu & \sim N(6.5, \sigma_{\mu})\\
\end{align*}



* According to this prior, there is about 95% probability of $\mu$ lying in (6.4, 6.6). 

\bigskip

* Parameter $\sigma_{\mu}$ represents our prior uncertainty on the value of $\mu$. 


\bigskip

* This prior expresses information about the value of  $\mu$, the average hyppocampal volume within the population.

\bigskip

* There is no single right prior, but multiple reasonable priors!


# Likelihood

* We now provide a model for the distribution of 
 the hippocampal volumes, assuming to measure $n$ subjects.

\bigskip


* We make a *second* assumption of normality.

\bigskip

* The measured hippocampal volumes $y_1,y_2,…,y_n$, are independent and normally distributed around  $\mu$, with standard deviation $\sigma$.



* $\sigma$ expresses the spread of the hippocampal volumes within the population.

\bigskip

* As we expect the volume to vary between roughly 6 and 7, we  set $\sigma$=0.25 (we interpret the interval as $\mu \pm 2\sigma$, hence it has length of 4$\sigma$).

\bigskip

* Have clear the difference between $\sigma$ and $\sigma_{\mu}$!


# Likelihood


<!-- \bigskip -->


<!-- * The dependence of $y_i$ on the unknown mean $\mu$ is: -->
<!-- $$y_i \mid \mu ∼ N(\mu,\sigma)$$ -->

<!-- \bigksip -->

<!-- * The Normal model let  each subject’s hippocampal volume  range from $-\infty$ to $\infty$. However, we’re not worried: it  puts negligible weight on unreasonable values. -->

# Likelihood

The joint pdf which describes the collective randomness in our $n$ subjects’ hippocampal volumes, ($y_1,y_2,…,y_n$), is the product of the unique Normal pdfs $f(y_i \mid \mu)$:

$$
f(\vec{y} | \mu) = \prod_{i=1}^{n}f(y_i|\mu) = \prod_{i=1}^{n}\frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg[{-\frac{(y_i-\mu)^2}{2\sigma^2}}\bigg]  .
$$
\bigskip

* where $\vec{y}$ is the vector containing the measures $y_1,....y_n$.

* The Normal model let  each subject’s hippocampal volume  range from $-\infty$ to $\infty$. However, we’re not worried: it  puts negligible weight on unreasonable values.

# The Normal-Normal  model

\begin{align*}
\mu & \sim N(\mu', \sigma_{\mu}) \\
\vec{y} & \sim N(\mu, \sigma) \\
\end{align*}

* For the moment we assume $\sigma$ to be known and fixed. Later we will express our uncertainty also about it. 



# Conjugacy model

* Denote the sample mean as  $\bar{y} = \frac{1}{n} \sum_i y_i$.

\bigskip

* The posterior density of $\mu$ is 
 normal with updated parameters:

$$
\mu|\vec{y} \; \sim \;  N\bigg(\mu'\frac{\sigma^2}{n\sigma_{\mu}^2+\sigma^2} + \bar{y}\frac{n\sigma_{\mu}^2}{n\sigma_{\mu}^2+\sigma^2}, \; \frac{\sigma_{\mu}^2\sigma^2}{n\sigma_{\mu}^2+\sigma^2}\bigg)  .
$$
* where $\theta$ denotes

# The Normal-Normal Bayesian model

* The posterior mean is a weighted average of the prior mean $\mu'$ and the sample mean $\bar{y}$.


\bigskip

* As $n$ increases, the posterior mean places less weight on the prior mean and more weight on sample mean.

\bigskip

* As $n$ increases, the posterior variance decreases.

# The Normal-Normal Bayesian model

* Assume that the sample of $n$ measures has mean $\bar{y}=6.7$.

* The posterior pdf of $\mu$ is:

**conti da rifare**
$$
\mu | \vec{y} \; \sim \; N\bigg(6.5\cdot\frac{0.5^2}{25\cdot0.4^2+0.5^2} + 5.735\cdot\frac{25\cdot 0.4^2}{25 \cdot 0.4^2+0.5^2}, \; \frac{0.4^2\cdot0.5^2}{25\cdot0.4^2+0.5^2}\bigg).
$$

#  What if $\sigma$ is unknown?

*  A more sophisticated approach is to assign a prior to $\sigma$ and to make inference about it, rather than fixing it to a value.

\bigskip

* In this case there is no more closed-form expression of the posterior.

# Prior distribution of $\sigma$

*  $\sigma$ is strictly positive; a suitable prior is the *half-normal* distribution.

\bigskip

* The half-normal is  a Gaussian  restricted to positive values.

\bigskip
* You sample from a half-normal by sampling from a normal distribution and rejecting the negative values (or applying the absolute value to the  sampled values).


# The half-normal distribution

* The half-normal prior is a suitable choice for the standard deviation.


```{r, echo=FALSE, out.width = '75%', fig.cap= "from wikipedia"}
knitr::include_graphics("half_normal.png")
```


# The half-normal distribution

* The half-normal pdf is characterized by a scale parameter.

```{python, echo=FALSE, fig.height=2, fig.align="center"}
plt.figure(figsize=(10, 3))


x = np.linspace(-2,5, 100)

#at each x we plot the pdf of the halfnorm with different scales
plt.plot(x, halfnorm.pdf(x, scale=1), 'r-', lw=3, alpha=0.6, label='scale=1')
plt.plot(x, halfnorm.pdf(x, scale=3), 'b-', lw=3, alpha=0.6, label='scale=3');
plt.plot(x, halfnorm.pdf(x, scale=3), 'b-', lw=3, alpha=0.6, label='scale=5');
plt.legend()

```




# Tuning the half-normal distribution

* You can tune the HN prior distribution by matching its median with a plausible value of $\sigma$

\bigskip

* For instance  we think a plausible value for the standard deviation of the noise is 7.5.

\bigskip

  * with 95% probability the measures are lie in an interval of +- 15 around the mean.

\bigskip

* Of course, we are uncertain about this statament.

\bigskip

* Perhaps, with 95% probability the measures lie in an interval of +- 30, 
in which case the standard deviation of the noise is around 10.

# Tuning the half-normal distribution


\bigskip

* The HN pdf is asymmetric right-skewed pdf; it has long tails which are much larger than the median.

\bigskip

* It thus offer a broad range of plausible values.

* The prior should cover a wide range of plausible values for $\sigma$, leaving out however values that make no sense.


# Tuning the half-normal distribution

* The halfnormal distribution  has been obtained by trying different scale parameters.

\bigskip    

* Notice the long tails of the distribution, which allows to model to correct if our prior median guess (7.5) is underestimated.  

```{python, echo=TRUE, fig.height=2, fig.align="center"}
pd.DataFrame(halfnorm.rvs(size=1000, scale=11)).describe()
```
# The probabilistic model

\begin{align*}
\mu &\sim N(\mu_{\mu}, \sigma_{\mu}) && \text{prior beliefs about } \mu\\ 
\sigma &\sim \text{Half-Normal}(\sigma_{\sigma}) && \text{prior beliefs about } \sigma \\
y & \sim \mathcal{N}(\mu, \sigma) && \text{the observation are  affected by a noise with standard deviation } \sigma\\
\end{align*}

* We cannot treat this model analytically, as the prior are no longer conjugates.

\bigskip

* We will implement it later via probabilistic programming.

# Conceptual exercise

* Try to define the priors of a probabilistic model which  represents the distribution of height of adult males in Switzerland 

# Population of Swiss adult males: $p(\mu)$


* The mean height of the population could  be 175, though this is uncertain. Keeping our prior broad,  the mean height of the population lies with 99% probability between 160 and 190 cm.
  
  \bigskip
  
  * $\mu \sim \mathcal{N}(175, 5)$ 
  
# Population of Swiss adult males: $p(\sigma)$

* We shall now assign a prior to $\sigma$. We assume that within the whole population the height  varies with 99% probability between 100 and 250. 

\bigskip

  * Hence the corresponding value of the standard deviation is (250-100)/6 = 25.
    
    \bigskip
    
  * Notice the broad but sensible range.
  
  \bigskip
    
  * A half-normal distribution with scale 35 has roughly this median:
  
      * $\sigma \sim \text{Half-Normal}(35)$

# Population of Swiss adult males: $p(\sigma)$

```{python, echo=TRUE, fig.height=2, fig.align="center"}
pd.DataFrame(halfnorm.rvs(size=1000, scale=35)).describe()
```

# Likelihood

* The likelihood  $y  \sim \mathcal{N}(\mu, \sigma)$ requires no parameter specification. 

\bigskip

* We are assuming that the measures are normally distributed around the mean.

\bigskip

* Moreover we assume that the measures are i.i.d.