---
title: "Marcov Chain Monte Carlo (MCMC)"
author: "Giorgio Corani - SUPSI"
date: ' Bayesian Data analysis and Probabilistic Programming'
output:
  beamer_presentation:
    latex_engine: xelatex
    fig_width: 6
    fig_height: 3
    highlight: tango
    theme: metropolis
    includes:
      in_header: header.tex
fontsize: 13pt
---


# Credits
* J. Krushke, "Doing Bayesian Data Analysis", Chapter 7



# Bayes' rule

* We denote the prior by $f(\theta)$,   the data by $D$,
the likelihood by $f(D \mid \theta)$.

\bigskip

* The computationally challenging part  of Bayes’ rule is  the denominator:

\begin{align*}
f(\theta \mid D) =
\frac{f(\theta) f(D \mid \theta)}{\underbrace{f(D)}_{\text{marg lik}}}
 =
\frac{p(\theta) p(D \mid \theta)}{\int p(\theta) p(D \mid \theta) d\theta}
\end{align*}

\bigskip

* In the conjugate case, we have an analytical expression of $f(\theta \mid D)$.

# Non-conjugate likelihood

* Generally the likelihood is **not**  conjugate to the prior.

\bigskip

* Is gridding a solution?
  * define a grid of values of the parameters 
  * for each point of the grid, compute the product (prior x likelihood)
  * normalize the obtained density


# Gridding does not scale

* The joint distribution of 6 parameters, each represented by 1000 states, has $1000^6$ states, too much for any computer.

# MCMC

* MCMC methods address this type of problems. 

\bigskip

* It  approximates  the posterior of $\theta$
by returning many samples.

\bigskip

* Doing so, it avoids computing  the difficult integral in the denominator of Bayes’ rule.

\bigskip

* For simplicity, we show  a single-parameter problem. 

\bigskip




#  Approximating a distribution with a (large) sample

* By randomly sampling a subset of people from a population, we can estimate the underlying tendencies in the entire population. 
\bigskip

* The larger the sample, the better the estimation. 
\bigskip

* The population from which we want to  sample is the **posterior distribution of $\theta$**.

#  Approximating a distribution by a large random sample
```{r, echo=FALSE, out.width = '45%'}
knitr::include_graphics("fig71.png")
```

* Larger samples yield a more accurate  histogram;

* The exact values (top-right) were obtained from the mathematical formula of the beta distribution. 


# The Metropolis algorithm: a simple example. 

* We live in a chain of 7 islands. 

\bigskip

* We have to do many travels, visiting  each  island proportionally to its population.

\bigskip

* We can move from an island to a neighboring one, or remain on the same island.

\bigskip

* The population of the different islands is 1000, 2000, 3000, ...,7000.

\bigskip

* This is the unnormalized distribution we want to sample from.


# Making decisions

* Flip a coin to decide whether the *proposed* island is  east or west of the current one.

\bigskip

* If it has a larger population than the current one, visit it.

\bigskip

* Otherwise, visit it with probability 

$$p_{\text{move}} = \frac{\text{pop}_{\text{proposed}}}{\text{pop}_{\text{current}}}$$


  * $\text{pop}_{\text{proposed}}$: population of the proposed island
  * $\text{pop}_{\text{current}}$: population of the current island.

\bigskip

* In the long run, each  island is visited proportionally to its population.

# Discussion 
* The proposed direction and its acceptance are random. 

\bigskip

* If the process were started over again, the specific trajectory would be  different. 

\bigskip

* Yet, in the long run the relative frequency of visits mimics in every case the target distribution.

# Proposal


*  The possible  moves and the probability of proposing each constitute the *proposal distribution*. 

\bigskip

* Our proposal distribution has only two values (left and right) with  probability 0.5 each.

# Accepting the proposal
* If the target distribution is greater at the proposed position,  we  accept the proposal: *we always move higher if we can*.

\bigskip
*  If the target distribution is less at the proposed position than at our current position, we accept the move with probability:

$$p_{\text{move}} = \frac{\text{pop}_{\text{proposed}}}{\text{pop}_{\text{current}}}$$ 

\bigskip
* More in general, we move to the proposed position with probability:

$$ p_{\text{move}} = min \left(  \frac {f(\theta_{\text{proposed}})} {f(\theta_{\text{current}})}, 1 \right) $$

where $f(\theta)$ is the unnormalized posterior  (see later).

# We use the *unnormalized* posterior

* The algorithm evaluates the ratio 
$\frac{f(\theta_{\text{proposed}})}{f(\theta_{\text{current}})}$,
without computing the normalizing constant (i.e., the denominator) of Bayes rule. 

\bigskip

* It does not require the 
 absolute value of $f(\theta|D)$, but only the ratio between the density in different locations.

\bigskip

* We  sample from $f(\theta)f(D|\theta)$ without normalizing  by the (often) untractable marginal likelihood $p(D)$.
 
 \bigskip
 
* In the example of  islands-hopping, the target distribution was the unnormalized population of each island, not a normalized probability.


# Random walk
* The samples from the posterior are generated by  a *random walk*

\bigskip

* The walk starts from a randomly chosen point where the distribution is non zero.

\bigskip

* At each time step we propose the move to a new position $\theta_{\text{proposed}}$.

\bigskip

* We accept the  move  with probability 
$$ p_{\text{move}} = min \left(  \frac {f(\theta_{\text{proposed}})} {f(\theta_{\text{current}})}, 1 \right) $$

#  Metropolis algorithm applied to the beta-binomial model

$f(\theta \mid D) \propto f(D \mid \theta) f(\theta) = \theta^{a+y-1} (1-\theta)^{b+n-y-1}$

\bigskip
*  $\theta$ is a continuous parameter 

\bigskip

*  Proposal distribution:  $\Delta \theta \sim N(0, \sigma)$.

\bigskip

* $\theta_{\text{proposed}}$  lies in an interval of $\pm 3 \sigma$ around $\theta_{\text{current}}$. 

\bigskip

* Hence $\sigma$ controls how far $\theta_{\text{proposed}}$  can be from $\theta_{\text{current}}$.

#  Sampling the beta-binomial

Randomly draw the starting point  $\theta_0 \in (0,1)$.

\bigskip

At each iteration:

* Draw $\Delta \theta \sim N(0, \sigma)$
* $\theta_{\text{proposed}} = \theta_{\text{current}} + \Delta \theta$

# Probability of the move

We move to $\theta_{\text{proposed}}$ with probability:

\begin{align*}
p & = \min \left( 1, \frac{f(\theta_{\text{proposed}} \mid D)}{f(\theta_{\text{current}} \mid D)}  \right) \\
& = \min \left( 1, \frac{\theta_{\text{proposed}}^{a+y-1} (1-\theta_{\text{proposed}})^{b+n-y-1}}{\theta_{\text{current}}^{a+y-1} (1-\theta_{\text{current}})^{b+n-y-1}}  \right) 
\end{align*}

# Application 
* Consider the prior $p(\theta)= Beta(1, 1)$

\bigskip

* The Bernoulli likelihood $\theta^{14} (1-\theta^{6})$ corresponds to 20 tosses and 14 tails.

\bigskip

* The three columns use three different $\sigma$ in the proposal distribution. 

# Results
![Approximating an exact mathematical distribution by a large random sample of representative values](fig74.png)

# Discussion

* $\frac{N_{\text{acc}}} {N_{\text{pro}}}$ denotes the probability of accepting a proposal.

\bigskip

* It decreases when $\sigma$ gets larger.

\bigskip

# Discussion

* The sequence of sampled values is called *trace*. The value of the trace are generally auto-correlated (i.e., the next sampled value is similar to the previous sampled value).

\bigskip

* Autocorrelation is stronger in the first column, medium in the second column, and strong again in third column.

\bigskip

* The *effective samples size* is  is the equivalent number of samples if they were sampled independently of each other (as the sampling is a sequential process, some auto-correlation in the samples is generally present).



# Left column (small $\sigma$)

*  The left column uses a the small $\sigma$ = 0.02.

\bigskip

* The successive steps in the chain make small moves

\bigskip

* This requires a very long chain to  explore the posterior distribution.

\bigskip

* The effective size of this 50,000 step chain is only 468.9.

# Right column (large $\sigma$)

* The proposed jumps are often far away from the bulk of the posterior distribution; the proposals are often rejected.

\bigskip

* The process rarely accepts new values, producing a  clumpy chain. 

\bigskip

* The effective size of this 50,000 step chain is only 2113.4.


# Discussion

* In no case we have 50,000 *independent* samples of the posterior. 

\bigskip

* The effective sample sizes are 468, 11723, 2113 in the three different scenarios.

\bigskip

* Tuning the width of the proposal distribution has a major impact on the effectivness of the sampling.

\bigskip

* In general good sampling is obtained when about 50% of the proposals is accepted (central column).

\bigskip

* Advanced implementations of the Metropolis algorithm  automatically  adjust the width of the proposal distribution.


# Your turn 

* Implement the island hopping algorithm

\bigskip

* Check that your visits are proportional to the population of the islands.


