set.seed(1)
#--------comparing mean and minimizer of ape
#parametri lognormale
m <- 100
s <- 10
density <- "normal"
#density <- "lognormal"
#a<-rnorm(10000, mean=m, sd=s)
#caso lognormale, vedi https://stats.stackexchange.com/questions/213897/best-way-to-optimize-mape
if (density=='normal')
a<-rnorm(10000, mean=m, sd=s)
if ( (density=='lognormal') )
a<-rlnorm(10000, mean=m, sd=s)
#discretized domain of y divided in 10000 steps
step <- (max(a) - min(a)) / 10000
y <- seq ( from=(min(a)), to=(max(a)), by=step)
#lognormal density
if  (density=='normal')
density <- dnorm(y, mean=m, sd=s)
if  (density=='lognormal')
density <- dlnorm(y, mean=m, sd=s)
df <- cbind(y, density, (density/y), 0)
colnames(df) <- c("y", "density","density/y","derived_cumulative")
##Build the derived density
df[1,"derived_cumulative"] <- df[1,"density/y"] * step
for (i in 2:nrow(df)){
df[i,"derived_cumulative"] <- df[i-1,"derived_cumulative"] +  df[i,"density/y"] * step
}
#non sembra funzionare...
df[,"derived_cumulative"] <- df[,"derived_cumulative"]/df[nrow(df),"derived_cumulative"]
#lookup to find the median
pe_minimizer<- approx(df[,"derived_cumulative"], df[,"y"], xout = 0.5)$y
#0.366
mse_pe_minimizer <- mean( ((a - pe_minimizer)^2) ) #6.05
mpe_pe_minimizer <- mean( abs(abs(a - pe_minimizer)/a) ) #0.69
#using mean as point forecast
mean_a <- mean(a)
mse_mean_a <- mean( ((a - mean_a)^2) ) #4.41
mpe_mean_a <- mean( abs(abs(a - mean_a)/a) ) #2.03
print("media, minimizer")
print(c(mpe_mean_a, mpe_pe_minimizer))
set.seed(1)
#--------comparing mean and minimizer of ape
#parametri lognormale
m <- 100
s <- 20
density <- "normal"
#density <- "lognormal"
#a<-rnorm(10000, mean=m, sd=s)
#caso lognormale, vedi https://stats.stackexchange.com/questions/213897/best-way-to-optimize-mape
if (density=='normal')
a<-rnorm(10000, mean=m, sd=s)
if ( (density=='lognormal') )
a<-rlnorm(10000, mean=m, sd=s)
#discretized domain of y divided in 10000 steps
step <- (max(a) - min(a)) / 10000
y <- seq ( from=(min(a)), to=(max(a)), by=step)
#lognormal density
if  (density=='normal')
density <- dnorm(y, mean=m, sd=s)
if  (density=='lognormal')
density <- dlnorm(y, mean=m, sd=s)
df <- cbind(y, density, (density/y), 0)
colnames(df) <- c("y", "density","density/y","derived_cumulative")
##Build the derived density
df[1,"derived_cumulative"] <- df[1,"density/y"] * step
for (i in 2:nrow(df)){
df[i,"derived_cumulative"] <- df[i-1,"derived_cumulative"] +  df[i,"density/y"] * step
}
#non sembra funzionare...
df[,"derived_cumulative"] <- df[,"derived_cumulative"]/df[nrow(df),"derived_cumulative"]
#lookup to find the median
pe_minimizer<- approx(df[,"derived_cumulative"], df[,"y"], xout = 0.5)$y
#0.366
mse_pe_minimizer <- mean( ((a - pe_minimizer)^2) ) #6.05
mpe_pe_minimizer <- mean( abs(abs(a - pe_minimizer)/a) ) #0.69
#using mean as point forecast
mean_a <- mean(a)
mse_mean_a <- mean( ((a - mean_a)^2) ) #4.41
mpe_mean_a <- mean( abs(abs(a - mean_a)/a) ) #2.03
print("media, minimizer")
print(c(mpe_mean_a, mpe_pe_minimizer))
(177 - 173)/175
set.seed(1)
#--------comparing mean and minimizer of ape
#parametri lognormale
m <- 100
s <- 30
density <- "normal"
#density <- "lognormal"
#a<-rnorm(10000, mean=m, sd=s)
#caso lognormale, vedi https://stats.stackexchange.com/questions/213897/best-way-to-optimize-mape
if (density=='normal')
a<-rnorm(10000, mean=m, sd=s)
if ( (density=='lognormal') )
a<-rlnorm(10000, mean=m, sd=s)
#discretized domain of y divided in 10000 steps
step <- (max(a) - min(a)) / 10000
y <- seq ( from=(min(a)), to=(max(a)), by=step)
#lognormal density
if  (density=='normal')
density <- dnorm(y, mean=m, sd=s)
if  (density=='lognormal')
density <- dlnorm(y, mean=m, sd=s)
df <- cbind(y, density, (density/y), 0)
colnames(df) <- c("y", "density","density/y","derived_cumulative")
##Build the derived density
df[1,"derived_cumulative"] <- df[1,"density/y"] * step
for (i in 2:nrow(df)){
df[i,"derived_cumulative"] <- df[i-1,"derived_cumulative"] +  df[i,"density/y"] * step
}
#non sembra funzionare...
df[,"derived_cumulative"] <- df[,"derived_cumulative"]/df[nrow(df),"derived_cumulative"]
#lookup to find the median
pe_minimizer<- approx(df[,"derived_cumulative"], df[,"y"], xout = 0.5)$y
#0.366
mse_pe_minimizer <- mean( ((a - pe_minimizer)^2) ) #6.05
mpe_pe_minimizer <- mean( abs(abs(a - pe_minimizer)/a) ) #0.69
#using mean as point forecast
mean_a <- mean(a)
mse_mean_a <- mean( ((a - mean_a)^2) ) #4.41
mpe_mean_a <- mean( abs(abs(a - mean_a)/a) ) #2.03
print("media, minimizer")
print(c(mpe_mean_a, mpe_pe_minimizer))
(346 - 323) / 330
set.seed(1)
#--------comparing mean and minimizer of ape
#parametri lognormale
m <- 193
s <- 11
density <- "normal"
#density <- "lognormal"
#a<-rnorm(10000, mean=m, sd=s)
#caso lognormale, vedi https://stats.stackexchange.com/questions/213897/best-way-to-optimize-mape
if (density=='normal')
a<-rnorm(10000, mean=m, sd=s)
if ( (density=='lognormal') )
a<-rlnorm(10000, mean=m, sd=s)
#discretized domain of y divided in 10000 steps
step <- (max(a) - min(a)) / 10000
y <- seq ( from=(min(a)), to=(max(a)), by=step)
#lognormal density
if  (density=='normal')
density <- dnorm(y, mean=m, sd=s)
if  (density=='lognormal')
density <- dlnorm(y, mean=m, sd=s)
df <- cbind(y, density, (density/y), 0)
colnames(df) <- c("y", "density","density/y","derived_cumulative")
##Build the derived density
df[1,"derived_cumulative"] <- df[1,"density/y"] * step
for (i in 2:nrow(df)){
df[i,"derived_cumulative"] <- df[i-1,"derived_cumulative"] +  df[i,"density/y"] * step
}
#non sembra funzionare...
df[,"derived_cumulative"] <- df[,"derived_cumulative"]/df[nrow(df),"derived_cumulative"]
#lookup to find the median
pe_minimizer<- approx(df[,"derived_cumulative"], df[,"y"], xout = 0.5)$y
#0.366
mse_pe_minimizer <- mean( ((a - pe_minimizer)^2) ) #6.05
mpe_pe_minimizer <- mean( abs(abs(a - pe_minimizer)/a) ) #0.69
#using mean as point forecast
mean_a <- mean(a)
mse_mean_a <- mean( ((a - mean_a)^2) ) #4.41
mpe_mean_a <- mean( abs(abs(a - mean_a)/a) ) #2.03
print("media, minimizer")
print(c(mpe_mean_a, mpe_pe_minimizer))
(0.04628467 - 0.04619630) / 0.04619630
library(bayesrule)
library(bayesrules)
data("bikes")
force(bikes)
View(bikes)
pwd()
setwd("~/switchdrive/teaching/BayesianProg/bda/rmd")
write.csv(bikes, file="bikes.csv",row.names = FALSE, col.names = TRUE )
library(showtext)
install.packages("showtext")
library(tidyverse)
library(ggplot2)
library(showtext)
font_add_google("Playfair Display", ## name of Google font
"Playfair")  ## name that will be used in R
font_add_google("Bangers", "Bangers")
library(tidyverse)
library(ggplot2)
library(showtext)
font_add_google("Playfair Display", "Playfair")
A <- rnorm(10000)
var(A)
var(A+A)
#2 variabili molto correlate
Sigma <- matrix(data=(1,1,0,0,1,1,0,0,1))
#2 variabili molto correlate
Sigma <- matrix(data=c(1,1,0,0,1,1,0,0,1))
#2 variabili molto correlate
Sigma <- matrix(data=c(1,1,0,0,1,1,0,0,1), nrow = 3)
Sigma
ev <- eigen(Sigma)
vectors <- ev$vectors
vectors
vectors <- t(ev$vectors)
vector()
vectors
vectors <- t(ev$vectors)
vectors
vectors <- ev$vectors
vectors
eigen(Sigma)
#2 variabili molto correlate
Sigma <- matrix(data=c(1,1,0,0,1,1,0,0,1), nrow = 3)
ev <- eigen(Sigma)
vectors <- ev$vectors
#2 variabili molto correlate
library(MASS)
x <- mvrnorm(n = 1000, mu = c(0,0,0), Sigma)
Sigma <- matrix(data=c(1,1,0,0,1,1,0,0,1), nrow = 3)
x <- mvrnorm(n = 1000, mu = c(0,0,0), Sigma)
Sigma
Sigma <- matrix(data=c(1,1,0,0,1,1,0,0,1), nrow = 3, byrow = TRUE)
x <- mvrnorm(n = 1000, mu = c(0,0,0), Sigma)
Sigma
Sigma <- matrix(data=c(1,1,0,1,1,0,0,0,1), nrow = 3, byrow = TRUE)
x <- mvrnorm(n = 1000, mu = c(0,0,0), Sigma)
Sigma <- matrix(data=c(1,0.8,0,1,1,0,0,0,1), nrow = 3, byrow = TRUE)
x <- mvrnorm(n = 1000, mu = c(0,0,0), Sigma)
Sigma
Sigma <- matrix(data=c(1,0.8,0,0.8,1,0,0,0,1), nrow = 3, byrow = TRUE)
Sigma
ev <- eigen(Sigma)
vectors <- ev$vectors
vectors
dim(x)
A <- ev$vectors
A
x <- t(mvrnorm(n = 1000, mu = c(0,0,0), Sigma))
ev <- eigen(Sigma)
A <- ev$vectors
y = t(A) %*% x
dim(y)
?eigen
a<-eigen(Sigma)
a
a$values
a$vectors
dim(x)
dim(y)
cor(y)
cor(t(y))
y = t (t(A) %*% x)
cor(y)
var(y)
apply(y, MARGIN = 2, var)
eigen(x)
eigen(Sigma)
.9/.1
(.9/.1)^2
hist(rchisq(10000,df=1))
summary(rchisq(10000,df=1))
z[1] <- y[1]
z[1] <- y[1]
y <- rnorm(n=10000)
gamma <- .7
z <- vector(0, length = length(y))
z <- vector(length = length(y))
z
z[1] <- y[1]
for (i in (2:length(z))) {
z <- gamma * y[i] + (1 - gamma) * z[i-1]
}
z
z
z[1] <- y[1]
for (i in (2:length(z))) {
z[i] <- gamma * y[i] + (1 - gamma) * z[i-1]
}
i
z[1] <- y[1]
for (i in (2:length(z))) {
z[i] <- gamma * y[i] + (1 - gamma) * z[i-1]
}
z
z <- rep(1,10000)
z[1] <- y[1]
for (i in (2:length(z))) {
z[i] <- gamma * y[i] + (1 - gamma) * z[i-1]
}
##
samples <- 10000
y <- rnorm(n=samples)
gamma <- .7
z <- rep(1,samples)
z[1] <- y[1]
for (i in (2:length(z))) {
z[i] <- gamma * y[i] + (1 - gamma) * z[i-1]
}
z
mean(z)
var(z)
gamma
.7  / .3
(.7  / .3) ^2
y[1]
z[1]
z[2]
gamma * y[2] + (1-gamma) * z[1]
z[2]
hist(z)
##
samples <- 100000
y <- rnorm(n=samples)
gamma <- .7
z <- rep(1,samples)
z[1] <- y[1]
hist(z)
##
samples <- 100000
y <- rnorm(n=samples)
gamma <- .7
z <- rep(1,samples)
z[1] <- y[1]
length(z)
for (i in (2:length(z))) {
z[i] <- gamma * y[i] + (1 - gamma) * z[i-1]
}
z
hist(z)
summary(z)
sd(z)
gamma/(1-gamma)
var(z)
(1-gamma)/gamma
(gamma^2 )/(1-gamma)^2
var(z)
gamma / (2-gamma)
set.seed(0)
Sigma <- rWishart(1, p, diag(1, nrow = 3))
#simulate covariance matrix
p <- 3
diag_mat <- diag(1, nrow = 3)
Sigma <- rWishart(1, p, diag_mat)
Sigma
#generate random covariance matrix
p <- 3
#generate random covariance matrix
p <- 3
diag_mat <- diag(1, nrow = 3)
Sigma <- rWishart(1, p, diag_mat)
Sigma <- matrix(data=c(1,0.8,0,0.8,1,0,0,0,1), nrow = 3, byrow = TRUE)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = rep(0,p), Sigma))
#generate random covariance matrix
p <- 100
diag_mat <- diag(1, nrow = p)
Sigma <- rWishart(1, p, diag_mat)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = rep(0,p), Sigma))
#generate random covariance matrix
p <- 100
diag_mat <- diag(1, nrow = p)
diag_mat
#generate random covariance matrix
p <- 10
diag_mat <- diag(1, nrow = p)
diag_mat
Sigma <- rWishart(1, p, diag_mat)
Sigma
#Fase 1
x <- t(mvrnorm(n = 1000, mu = rep(0,p), Sigma))
?mvrnorm
rep(0,p)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
dim(Sigma)
as.matrix(Sigma)
dim(as.matrix(Sigma))
dim(as.matrix(Sigma, nrow=p))
dim(as.matrix(Sigma, nrow=p))
dim(matrix(Sigma, nrow=p))
matrix(Sigma, nrow=p)
#generate random covariance matrix
p <- 10
diag_mat <- diag(1, nrow = p)
Sigma <- rWishart(1, p, diag_mat)
Sigma <- matrix(Sigma,  nrow = p)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
ev <- eigen(Sigma)
A <- ev$vectors
y = t (t(A) %*% x)
cor(y)
ev$values
apply(x, MARGIN = 1, var)
sort(apply(x, MARGIN = 1, var))
sort(ev$values)
apply(y, MARGIN = 1, var)
apply(y, MARGIN = 2, var)
sort(apply(y, MARGIN = 2, var))
sort(ev$values)
ev$vectors
ev$values
sort(ev$values)
sort(ev$values, decreasing = TRUE)
#need to sort the columns of y according to the eigenvalues
order(ev$values)
ev$values
?ev
?eigven
?eigen
?order
#need to sort the columns of y according to the eigenvalues
order(ev$values, decreasing = TRUE)
ev$values
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
diag_mat <- diag(1, nrow = p)
Sigma <- rWishart(1, p, diag_mat)
Sigma <- matrix(Sigma,  nrow = p)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
ev <- eigen(Sigma)
A <- ev$vectors
y = t (t(A) %*% x)
#double check
cor(y) #almost diagonal
sort(apply(y, MARGIN = 2, var)) #variance of the y, very close to eigenvalues
sort(ev$values) #sorted eigenvalues
#2 variabili molto correlate
library(MASS)
set.seed(0)
#generate random covariance matrix
p <- 10
diag_mat <- diag(1, nrow = p)
Sigma <- rWishart(1, p, diag_mat)
Sigma <- matrix(Sigma,  nrow = p)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
ev <- eigen(Sigma)
A <- ev$vectors
y = t (t(A) %*% x)
#need to sort the columns of y according to the eigenvalues
order(ev$values, decreasing = TRUE)
ev$values
set.seed(0)
#generate random covariance matrix
p <- 10
diag_mat <- diag(1, nrow = p)
Sigma <- rWishart(1, p, diag_mat)
Sigma <- matrix(Sigma,  nrow = p)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
ev <- eigen(Sigma)
A <- ev$vectors
y = t (t(A) %*% x)
#need to sort the columns of y according to the eigenvalues
order(ev$values, decreasing = TRUE)
ev$values
ev$values
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
ev <- eigen(Sigma)
A <- ev$vectors
y = t (t(A) %*% x)
ev$vectors
var(y)
apply(y, 2, var)
#2 variabili molto correlate
library(MASS)
set.seed(0)
#generate random covariance matrix
p <- 10
diag_mat <- diag(1, nrow = p)
Sigma <- rWishart(1, p, diag_mat)
#2 variabili molto correlate
library(MASS)
set.seed(0)
#generate random covariance matrix
p <- 10
diag_mat <- diag(1, nrow = p)
Sigma <- rWishart(1, p, diag_mat)
Sigma <- matrix(Sigma,  nrow = p)
#Fase 1
x <- t(mvrnorm(n = 1000, mu = t(rep(0,p)), Sigma))
ev <- eigen(Sigma)
A <- ev$vectors
y = t (t(A) %*% x)
#double check
cor(y) #almost diagonal
sort(apply(y, MARGIN = 2, var)) #variance of the y, very close to eigenvalues
sort(ev$values) #sorted eigenvalues
ev$values
#double check
cor(y) #almost diagonal
apply(y, MARGIN = 2, var) #variance of the y, very close to eigenvalues
ev$values #sortede eigenvalues
dim(y)
#standardized y
y_tilde <- y/sqrt(ev.values)
#standardized y
y_tilde <- y/sqrt(ev$values)
apply(y,2,var)
apply(y_tilde,2,var)
ev$values[1]
ev$values[2\]
ev$values[2]
for (i in 1:ncol(y_tilde)){
y_tilde[,i] <- y_tilde[,i]/sqrt(ev$values[i])
}
#standardized y
for (i in 1:ncol(y_tilde)){
y_tilde[,i] <- y[,i]/sqrt(ev$values[i])
}
apply(y_tilde, MARGIN = 2, var)
