cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- 1/abs(i-j)
}
}
View(cor_matrix)
View(cor_matrix)
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- 1/(i-j)^2
}
}
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- exp( - ((i-j)^2) )
}
}
cor_matrix
cov_matrix <- cor_matrix * s^2;
cov_matrix
/** convert correlation matrix to covariance matrix **/
/** convert correlation matrix to covariance matrix **/
R = c(1.00, 0.25, 0.90, 0.25, 1.00, 0.50, 0.90, 0.50, 1.00)
D = diag(4)
D
?diag
D = diag(4, nrow = 3)
D
S = D %*% R %*% D
R = matrix(c(1.00, 0.25, 0.90, 0.25, 1.00, 0.50, 0.90, 0.50, 1.00), nrow=3)
D = diag(4, nrow = 3)
S = D %*% R %*% D
D
S
R = matrix(c(1.00, 0.25, 0.90, 0.25, 1.00, 0.50, 0.90, 0.50, 1.00), nrow=3, byrow = TRUE)
R = matrix(c(1.00, 0.25, 0.90, 0.25, 1.00, 0.50, 0.90, 0.50, 1.00), nrow=3, byrow = TRUE)
D = diag(4, nrow = 3)
S = D %*% R %*% D
S
R
R * 16
cov_matrix <- cor_matrix * s^2
#Here I  create a fictitious cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- exp( - ((i-j)^2) )
}
}
cov_matrix <- cor_matrix * s^2
library(MASS)
#---samples 10000 times from a MVN
#the mean is the mean forecast, the Sigma is cov_matrix
future_fcast <- mvrnorm(n = 10000, mu=m, Sigma=cov_matrix)
future_fcast
?which.max
max.row
?max.row
?max
?max.col()
?max.col
#probability of each hour providing the max
max_idx <- apply(future_fcast, which.max)
?apply
#probability of each hour providing the max
max_idx <- apply(future_fcast, 1, which.max)
max_idx
dim(max_idx)
length(max_idx)
future_fcast <- cbind(future_fcast,max_idx)
View(future_fcast)
View(future_fcast)
?table
colnames(future_fcast)
table(max_idx)
#how many times each hour is the maximum
count_table <- table(max_idx)
table
count_table
count_table/sum(count_table)
class(count_table)
names(count_table)
as.numeric(names(count_table))
as.numeric((count_table))
#probability mass function for the maxima
pmf <- df(cbind(as.numeric(names(count_table))),
as.numeric((count_table))/sum(count_table) )
#probability mass function for the maxima
pmf <- df(cbind(
#probability mass function for the maxima
pmf <- df(cbind(
as.numeric(names(count_table)),
as.numeric(count_table)/sum(count_table)
))
as.numeric(names(count_table)),
as.numeric(names(count_table))
as.numeric(count_table)/sum(count_table)
cbind(
as.numeric(names(count_table)),
as.numeric(count_table)/sum(count_table)
)
df(cbind(
as.numeric(names(count_table)),
as.numeric(count_table)/sum(count_table)
))
#probability mass function for the maxima
pmf <- data.frame(cbind(
as.numeric(names(count_table)),
as.numeric(count_table)/sum(count_table)
))
pmf
pmf
zeros
ones
#probability mass function for the maxima
pmf <- data.frame(cbind(
as.numeric(names(count_table)),
as.numeric(count_table)/sum(count_table),
#third column will be overwritten
vector(0, length = length(count_table))
))
?vector
vector(length = length(count_table), x=0)
vector(length = length(count_table), 0)
#probability mass function for the maxima
pmf <- data.frame(cbind(
as.numeric(names(count_table)),
as.numeric(count_table)/sum(count_table),
#third column will be overwritten
1:length(count_table)
))
pmf
#probability mass function for the maxima
hour <- as.numeric(names(count_table))
pmf  <- as.numeric(count_table)/sum(count_table)
functional <- pmf / hour
functional <- pmf / hour
functional <- functional / sum(functional)
functional
df <- data.frame(hour, pmf, functional)
df
sum(df[,"functional"])
cumsum(df[,"functional"])
df$hour
#find the median according to the density
#defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional)
df$functional
#find the median according to the density
#defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional,
replace = TRUE)
sample
median(sample)
ape_minimizer <- median(sample)
colnames(future_fcast)
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
mae_mode
mode
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
mae_ape_minimizer <-
mean( abs(future_fcast[,"max_idx"] - ape_minimizer))
pe_mode <-
mean( abs(future_fcast[,"max_idx"] - mode) / abs(future_fcast[,"max_idx"]) )
ape_mode
ape_mode <-
mean( abs(future_fcast[,"max_idx"] - mode) / abs(future_fcast[,"max_idx"]) )
ape_mode
ape_ape_minimizer <-
mean( abs(future_fcast[,"max_idx"] - ape_minimizer) / abs(future_fcast[,"max_idx"]))
ape_ape_minimizer
#generate data
m <- 8
s <- 2
a<-rnorm(10000, mean=m, sd=s)
#discretized domain of y, m +-3s, density and density/y
y <- seq ( from=(m-3*s), to=(m+3*s), by=0.1)
density <- dnorm(y, mean=m, sd=s)
df <- cbind(y, density, (density/y))
colnames(df) <- c("y", "density","functional")
median_func <- median(df[,"functional"])
#the point fcast which minimizes ape is the value of y
#corresponding to the median of the functional
idx <- which(df[,"functional"]==median_func)
pf_ape <- df[idx,"y"]
#indeed, pf_ape has larger mae but smaller mape than the mean
mae_mean <- mean(abs(y - m)) #3.02
mae_pf   <- mean(abs(y - pf_ape)) #4.09
mpe_mean <- mean( abs(abs(y - m)/y) ) #0.560
mpe_ape_minimizer <- mean( abs(abs(y - pf_ape)/y) ) #0.468
ape_minimizer <- df[idx,"y"]
ape_minimizer
#indeed, pf_ape has larger mae but smaller mape than the mean
mae_mean <- mean(abs(y - m)) #3.02
mae_ape_minimizer   <- mean(abs(y - pf_ape)) #4.09
mpe_mean <- mean( abs(abs(y - m)/y) ) #0.560
mpe_ape_minimizer <- mean( abs(abs(y - pf_ape)/y) ) #0.468
#these is an example forecast considerinfg the next 12 hours for simplicity
#in a real implementation we should cover the next 24 hours.
#each forecast is assumed to be normal density with sd 2
#the shape of the mean forecast is bimodal
num_hours <- 12
m <- vector(length = num_hours)
m <- c(1, 1, 2, 3, 5, 8, 6, 4, 3, 2, 5, 7)
#these is an example forecast considerinfg the next 12 hours for simplicity
#in a real implementation we should cover the next 24 hours.
#each forecast is assumed to be normal density with sd 2
#the shape of the mean forecast is bimodal
num_hours <- 12
m <- vector(length = num_hours)
m <- c(1, 1, 2, 3, 5, 8, 6, 4, 3, 2, 5, 7)
df <- data.frame(cbind(seq(1,num_hours)), m)
colnames(df) <- c("hour","mean_fcast")
s <- 2
#our current fcast
mode <- max(m)
#Here I  create a fictitious cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- exp( - ((i-j)^2) )
}
}
cov_matrix <- cor_matrix * s^2
#---samples 10000 times from a MVN
#the mean is the mean forecast, the Sigma is cov_matrix
future_fcast <- mvrnorm(n = 10000, mu=m, Sigma=cov_matrix)
#---probability of each hour providing the max
#we get the index of the maximum
max_idx <- apply(future_fcast, 1, which.max)
#how many times each hour is the maximum
count_table <- table(max_idx)
#probability mass function for the maxima
hour <- as.numeric(names(count_table))
pmf  <- as.numeric(count_table)/sum(count_table)
functional <- pmf / hour
functional <- functional / sum(functional)
df <- data.frame(hour, pmf, functional)
#find the median according to the density
#defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional,
replace = TRUE)
ape_minimizer <- median(sample)
ape_minimizer
mode
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
#our current fcast
mode <- which.max(m)
#these is an example forecast considerinfg the next 12 hours for simplicity
#in a real implementation we should cover the next 24 hours.
#each forecast is assumed to be normal density with sd 2
#the shape of the mean forecast is bimodal
num_hours <- 12
m <- vector(length = num_hours)
m <- c(1, 1, 2, 3, 5, 8, 6, 4, 3, 2, 5, 7)
df <- data.frame(cbind(seq(1,num_hours)), m)
colnames(df) <- c("hour","mean_fcast")
s <- 2
#our current fcast
mode <- which.max(m)
source("~/Downloads/hour_of_peak.R", echo=TRUE)
#Here I  create a fictitious cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- exp( - ((i-j)^2) )
}
}
cov_matrix <- cor_matrix * s^2
#---samples 10000 times from a MVN
#the mean is the mean forecast, the Sigma is cov_matrix
future_fcast <- mvrnorm(n = 10000, mu=m, Sigma=cov_matrix)
#---probability of each hour providing the max
#we get the index of the maximum
max_idx <- apply(future_fcast, 1, which.max)
#how many times each hour is the maximum
count_table <- table(max_idx)
#probability mass function for the maxima
hour <- as.numeric(names(count_table))
pmf  <- as.numeric(count_table)/sum(count_table)
functional <- pmf / hour
functional <- functional / sum(functional)
df <- data.frame(hour, pmf, functional)
#find the median according to the density
#defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional,
replace = TRUE)
ape_minimizer <- median(sample)
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
ape_minimizer
mode
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
#these is an example forecast considerinfg the next 12 hours for simplicity
#in a real implementation we should cover the next 24 hours.
#each forecast is assumed to be normal density with sd 2
#the shape of the mean forecast is bimodal
num_hours <- 12
m <- vector(length = num_hours)
m <- c(1, 1, 2, 3, 5, 8, 6, 4, 3, 2, 5, 7)
df <- data.frame(cbind(seq(1,num_hours)), m)
colnames(df) <- c("hour","mean_fcast")
s <- 2
#our current fcast
mode <- which.max(m)
#Here I  create a fictitious cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- exp( - ((i-j)^2) )
}
}
cov_matrix <- cor_matrix * s^2
#---samples 10000 times from a MVN
#the mean is the mean forecast, the Sigma is cov_matrix
future_fcast <- mvrnorm(n = 10000, mu=m, Sigma=cov_matrix)
#---probability of each hour providing the max
#we get the index of the maximum
max_idx <- apply(future_fcast, 1, which.max)
#how many times each hour is the maximum
count_table <- table(max_idx)
#probability mass function for the maxima
hour <- as.numeric(names(count_table))
pmf  <- as.numeric(count_table)/sum(count_table)
functional <- pmf / hour
functional <- functional / sum(functional)
df <- data.frame(hour, pmf, functional)
#find the median according to the density
#defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional,
replace = TRUE)
ape_minimizer <- median(sample)
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
mae_ape_minimizer <-
mean( abs(future_fcast[,"max_idx"] - ape_minimizer))
mae_mode <- mean( abs(future_fcast[,"max_idx"] - mode))
future_fcast
colnames(future_fcast)
future_fcast
library(fpp2)
?tsCV
set.seed(1)
library(MASS)
#these is an example forecast considerinfg the next 12 hours for simplicity
#in a real implementation we should cover the next 24 hours.
#each forecast is assumed to be normal density with sd 2
#the shape of the mean forecast is bimodal
num_hours <- 12
m <- vector(length = num_hours)
m <- c(1, 1, 2, 3, 5, 8, 6, 4, 3, 2, 5, 7)
df <- data.frame(cbind(seq(1,num_hours)), m)
colnames(df) <- c("hour","mean_fcast")
s <- 2
#our current fcast
mode <- which.max(m)
#Here I  create a fictitious cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
mode
#Here I  create a fictitious cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- exp( - ((i-j)^2) )
}
}
cov_matrix <- cor_matrix * s^2
cov_matrix
cor_matrix
#---samples 10000 times from a MVN
#the mean is the mean forecast, the Sigma is cov_matrix
future_fcast <- mvrnorm(n = 10000, mu=m, Sigma=cov_matrix)
#---probability of each hour providing the max
#we get the index of the maximum
max_idx <- apply(future_fcast, 1, which.max)
#how many times each hour is the maximum
count_table <- table(max_idx)
#probability mass function for the maxima
hour <- as.numeric(names(count_table))
pmf  <- as.numeric(count_table)/sum(count_table)
functional <- pmf / hour
functional <- functional / sum(functional)
df <- data.frame(hour, pmf, functional)
#find the median according to the density
#defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional,
replace = TRUE)
ape_minimizer <- median(sample)
#find the median by sampling from  the density defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional,
replace = TRUE)
ape_minimizer <- median(sample)
mae_mode <- mean( abs(max_idx - mode))
mae_mode <- mean( abs(max_idx - mode))
mae_ape_minimizer <-
mean(max_idx - ape_minimizer))
mae_mode <- mean( abs(max_idx - mode))
mae_ape_minimizer <- mean( abs(max_idx - ape_minimizer) )
mae_mode`
mae_mode <- mean( abs(max_idx - mode))
mae_mode
ape_minimizer
mae_ape_minimizer <- mean( abs(max_idx - ape_minimizer) )
mae_ape_minimizer
mape_mode <-
mean( abs(max_idx - mode) / abs(future_fcast[,"max_idx"]) )
mape_ape_minimizer <-
mean( abs(max_idx - ape_minimizer) / abs(future_fcast[,"max_idx"]))
mape_mode <-  mean( abs(max_idx - mode) / max_idx) )
mape_mode <-  mean( abs(max_idx - mode) / max_idx)
mape_mode <-  mean( abs(max_idx - mode) / max_idx)
mape_ape_minimizer <- mean( abs(max_idx - ape_minimizer) / max_idx)
mape_mode
mape_ape_minimizer
#these is an example forecast considerinfg the next 12 hours for simplicity
#in a real implementation we should cover the next 24 hours.
#each forecast is assumed to be normal density with sd 2
#the shape of the mean forecast is bimodal
num_hours <- 12
m <- vector(length = num_hours)
m <- c(1, 1, 2, 3, 5, 6, 6, 4, 3, 2, 5, 9)
df <- data.frame(cbind(seq(1,num_hours)), m)
colnames(df) <- c("hour","mean_fcast")
s <- 2
#our current fcast
mode <- which.max(m)
mode
#Here I  create a fictitious cor_matrix
#diagonal matrix with 1 on the diagonals
cor_matrix <- diag(num_hours)
for (i in (1:num_hours)){
for (j in (1:num_hours))
{
if (i==j)
next
else
cor_matrix[i,j] <- exp( - ((i-j)^2) )
}
}
cov_matrix <- cor_matrix * s^2
#---samples 10000 times from a MVN
#the mean is the mean forecast, the Sigma is cov_matrix
future_fcast <- mvrnorm(n = 10000, mu=m, Sigma=cov_matrix)
#---probability of each hour providing the max
#we get the index of the maximum
max_idx <- apply(future_fcast, 1, which.max)
#how many times each hour is the maximum
count_table <- table(max_idx)
#probability mass function for the maxima
hour <- as.numeric(names(count_table))
pmf  <- as.numeric(count_table)/sum(count_table)
functional <- pmf / hour
functional <- functional / sum(functional)
df <- data.frame(hour, pmf, functional)
#find the median by sampling from  the density defined by the functional
sample <- sample(df$hour, size=10000, prob = df$functional,
replace = TRUE)
ape_minimizer <- median(sample)
ape_minimizer
mae_mode <- mean( abs(max_idx - mode))
mae_ape_minimizer <- mean( abs(max_idx - ape_minimizer) )
mape_mode <-  mean( abs(max_idx - mode) / max_idx)
mape_ape_minimizer <- mean( abs(max_idx - ape_minimizer) / max_idx)
source("~/Downloads/hour_of_peak.R", echo=TRUE)
mape_mode
mape_ape_minimizer
mode
ape_minimizer
df$functional
cumsum(df$functional)
