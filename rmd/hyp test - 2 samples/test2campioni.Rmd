---
title: "Test d'ipotesi per due campioni"
author: "Giorgio Corani  - (IDSIA, SUPSI)"
date: 'Statistica Applicata (G2A)'
output:
  beamer_presentation:
    latex_engine: xelatex
    fig_width: 7
    fig_height: 3.5
    highlight: tango
    theme: metropolis
    includes:
      in_header: header.tex
  slidy_presentation:
    highlight: tango
  ioslides_presentation:
    highlight: tango
fontsize: 13pt
editor_options: 
  markdown: 
    wrap: sentence
---



```{r, include=FALSE, out.width="80%"}
library(tidyverse)
library(ggplot2)
library(showtext)
library(ggthemes)
library(showtext)
library(reshape2)
library(kableExtra)
library(latex2exp)
```


# Testo di riferimento

*  Douglas P. Montgomery, *Introduction to Statistical Process Control*, 6th Edition, Wiley.

\bigskip


<!-- the line below is a piece of math which avoids compilation error -->
<!-- the first math cannot be an align environment -->
\sbox0{$x$}




# Confrontare due popolazioni

* Sinora abbiamo studiato test d'ipotesi e intervalli di confidenza riguardanti il parametro ($\mu$ o $\pi$) di una singola popolazione.

\bigskip

* Adesso studiamo come confrontare i parametri di due popolazioni.

# Confrontare due popolazioni


```{r, echo=FALSE, out.width = '85%', fig.align = 'center'}
knitr::include_graphics("two-populations.pdf", )
```


\bigskip

  * La prima popolazione ha media $\mu_1$ e  varianza $\sigma^2_1$.
  
  \bigskip

  * La seconda popolazione ha media $\mu_2$ e varianza $\sigma_2^2$. 


# Confrontare due popolazioni

```{r, echo=FALSE, out.width = '85%', fig.align = 'center'}
knitr::include_graphics("two-populations.pdf", )
```

* I due campioni hanno dimensione  $n_1$ e $n_2$.

\bigskip

* Assumiamo che i campioni siano estratti in modo *indipendente* dalle due popolazioni.

\bigskip

* Più avanti vedremo il caso dei campioni non indipendenti  (*appaiati*).

# Uguaglianza delle varianze 

* Assumiamo $\sigma_1^2 = \sigma_2^2$.

\bigskip

* Questa assunzione ci permette di stimare $\sigma^2$ facendo una media pesata di $s_1^2$  e  $s_2^2$. Questo è generalmente  più accurato rispetto a  stimare in modo indipendente le due varianze.



# Confrontare la media di due popolazioni

* Il test a  due code è:

\bigskip

\begin{align*}
H_0 \; &: \mu_1 = \mu_2\\
H_1 \; &: \mu_1 \neq \mu_2 \\
\end{align*}



# Test per due popolazioni

Sui due campioni misuriamo:

\bigskip

* $\bar{x}_1$ e $\bar{x}_2$: media del primo e del secondo campione.

\bigskip

*  $s_1^2$ e  $s_2^2$: varianza del primo e del secondo campione.

# Distribuzione campionaria di $\bar{x}_1 - \bar{x}_2$

* Supponiamo di estrarre molte volte due campioni di dimensioni $n_1$ e $n_2$  e di misurare ogni volta $\bar{x}_1 - \bar{x}_2$.

\bigskip 

* Assumendo:

  * che le due popolazioni abbiano la stessa varianza $\sigma^2$.

  *  $n_1$ e $n_2$  \textgreater 15-20 (per avere la normalità di $\bar{x}_1$ e $\bar{x}_2$):

 $$ \bar{x}_1 - \bar{x}_2 \sim N \left(  \mu_1 - \mu_2, \sigma^2  \left( \frac{1}{n_1}  +  \frac{1}{n_2}  \right) \right)$$


# Statistica con $\sigma$ nota

* Dato: 

 $$ \bar{x}_1 - \bar{x}_2 \sim N \left(  \mu_1 - \mu_2, \sigma^2  \left( \frac{1}{n_1}  +  \frac{1}{n_2}  \right) \right)$$

\bigskip

sotto $H_0$ abbiamo:

\begin{align*}
 \frac{\bar{x}_1 - \bar{x}_2
-  \overbrace{(\mu_1 - \mu_2)}^{\text{ipotizzato 0 in } H_0}}
 {\sigma \sqrt{ \left( \frac{1}{n_1}  +  \frac{1}{n_2} \right) }} = 
 \frac{\bar{x}_1 - \bar{x}_2}
 {\sigma \sqrt{ \left( \frac{1}{n_1}  +  \frac{1}{n_2} \right) }} \sim N (0  , 1)
\end{align*}


\bigskip

* Ma $\sigma$ è ignota e quindi non possiamo usare questa statistica.


# $t$-test




\bigskip

* La statistica del $t$ test è invece:

$$t = \frac{\bar{x}_1-\bar{x}_2} {s_P \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}$$

\bigskip

* che si distribuisce come una $t$ con ($n_1 + n_2 - 2$) gradi di libertà. 

*  $s_p$ sostituisce $\sigma$ ed è spiegato nella prossima slide.



# Varianza pesata


* Per  stimare  $\sigma^2$ usiamo la  media pesata di   $s_1^2$ e  $s_2^2$:

\bigskip

\begin{align*}
s^2_P &  = \frac{(n_1-1)}{n_1 + n_2 -2} \cdot s_1^2 + \frac{ (n_2-1)}{n_1 + n_2 -2} \cdot s_2^2 \\
s_P &  = \sqrt{s^2_P}
\end{align*}

\bigskip

* $s^2_P$: varianza  pesata (*pooled*)
  * i due pesi sono proporzionali  ai gradi di libertà dei due campioni.
  * se i campioni hanno uguale ampiezza, $s_p^2$ è la media  di $s_1^2$ e  $s_2^2$.

# La statistica del test

$$t = \frac{\bar{x}_1-\bar{x}_2} {s_P \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}$$

\bigskip

* $\bar{x}_1-\bar{x}_2$ è la stima di $\mu_1 - \mu_2$ in base ai dati del campione.

\bigskip

* $s_P \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$   è una stima della deviazione standard di $\bar{x}_1-\bar{x}_2$, che misura quanto $\bar{x}_1-\bar{x}_2$ è disperso attorno a $\mu_1 - \mu_2$





```{r child = 'regioni_rifiuto.Rmd'}
```


# Esempio:  resa di due catalizzatori

* Si confronta la resa di un processo chimico gestito dalla stessa azienda in due diversi impianti.

\bigskip

* Vogliamo testare se i due impianti hanno la stessa resa media.

\bigskip

* Facciamo quindi il test a due code:

\begin{align*}
H_0: \; & \mu_1 = \mu_2 \\
H_1: \; & \mu_1 \neq \mu_2 \\
\end{align*}

# Esempio:  resa di due catalizzatori

I dati ($n_1$ = $n_2$ = 8) sono:

\bigskip
* $\bar{x}_1$ = 92.25, $s_1$ =2.39
* $\bar{x}_2$ = 92.73, $s_2$ =2.98


\bigskip

* Svolgiamo il test con $\alpha$=0.05.

# Esempio:  resa di due catalizzatori


* Siccome $n_1$=$n_2$, $s^2_p$ è la media di $s_1^2$ e $s_2^2$:

\begin{align*}
s^2_p &= \frac{7}{14} s_1^2 + \frac{7}{14} s_2^2 =\frac{2.39^2 + 2.98^2}{2} = 7.3 \\
s_p &= \sqrt{s^2_p} = \sqrt{7.3} = 2.7
\end{align*}




# Statistica e valori critici

\begin{align*}
t_0 & = 
\frac{\bar{x}_1-\bar{x}_2}{
s_p     \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \\
\\
& = 
\frac{92.25 - 92.73}{2.7 \sqrt{\frac{1}{8} + \frac{1}{8}}} \\
\\
& = -0.35 \\
\end{align*}

* I valori critici sono $\pm t_{.975,14}=\pm 2.145$.

 


# Decisione

* La statistica è in regione di **non rifiuto**: non c'è evidenza che la resa dei due impianti sia diversa.

\bigskip

```{r echo=FALSE, out.width="90%", fig.align='center', warning=FALSE}
library(ggplot2)
library(ggthemes)
library(latex2exp)

tDistribution <- data.frame(
  x = seq(-4,4, by = 0.01),
  y = dt(seq(-4,4, by = 0.01), df=13)
)

critical <- qt(.975, df=13)

shadeRight <- rbind(c(critical,0), subset(tDistribution, x > critical))
shadeLeft <-  rbind(c(-critical,0), subset(tDistribution, x < -critical))


ggplot(tDistribution, aes(x,y)) +
  geom_line() +
  geom_polygon(data = shadeRight, aes(x=x, y=y, fill="red")) +
  geom_polygon(data = shadeLeft, aes(x=x, y=y, fill="red")) +
  #remove legend
  guides(fill="none") +
  theme_economist() +
  theme(text = element_text(size = 16)) +

  #remove labels
  ylab("") + xlab("") +

  #remove y ticks
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +

  scale_x_continuous(breaks=c(-critical, -0.35, critical),
                     labels = c(-2.145, -0.35, 2.145)) #+

```

# Intervallo di confidenza di $\mu_1 - \mu_2$

* L'intervallo  contiene i valori plausibili della differenza $\mu_1-\mu_2$: 

$$ \bar{x}_1 - \bar{x}_2 \pm t_{1-\alpha/2, n_1+n_2-2} \cdot s_P \sqrt{\frac{1}{n_1}+\frac{1}{n_2}} $$

\bigskip
  
* $t_{1-\alpha/2, n_1+n_2-2}$ :  quantile ($1-\alpha/2$) della $t$ con ($n_1+n_2-2$) gradi di libertà; corrisponde al valore critico del test.

\bigskip
  
* $s_P \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$ è il denominatore della statistica e rappresenta l'errore standard di $(\bar{x}_1 - \bar{x}_2)$

# Intervallo di confidenza vs test d'ipotesi



* Se l'ipotesi $\mu_1=\mu_2$ è plausibile alla luce dei dati disponibili: 
  * il test a due code non rifiuta $H_0$  
  * il CI contiene 0.
  
\bigskip

* Se l'ipotesi $\mu_1=\mu_2$ non è plausibile: 
  * il test a due code  rifiuta $H_0$  
  * il CI non contiene 0.

# Intervallo di confidenza (confidence interval, CI)

* I gradi di libertà sono 8-1+8-1 = 14

\bigskip

\begin{align*}
\bar{x}_1-\bar{x}_2 & \pm t_{.975,14} \cdot s_p \sqrt{\frac{1}{n_1}+\frac{1}{n_2}} \\
(92.25 - 92.73) & \pm 2.145 \cdot 2.7 \sqrt{\frac{1}{8}+\frac{1}{8}} =
(-3.38, 2.42)
\end{align*}


```{r, echo=FALSE, out.width = '85%', fig.align = 'center'}
low <- (92.25 - 92.73) + 2.145 * 2.7 * sqrt(1/8 + 1/8) 
up <- (92.25 - 92.73) - 2.145 * 2.7 * sqrt(1/8 + 1/8) 
```

\bigskip

* Lo 0 è uno dei   valori plausibili di $\mu_1-\mu_2$, in quanto contenuto dal  CI.

\bigskip

* Questo è coerente con l'esito del test,  che non rifiuta $H_0$.


# Esempio di test a una coda 

*  Uno studio riporta le percentuali di calcio misurate in cemento standard e cemento addizionato con piombo  (*doped*), al termine di uno stress test.

\bigskip

* Maggiori percentuali  di calcio indicano maggiore resistenza all'infiltrazione dell'acqua.

\bigskip

* Siccome il cemento doped  è più costoso, si richiede  forte evidenza che contenga una maggiore percentuale di calcio rispetto a quello standard.

\bigskip

* Svolgere il test usando $\alpha$=0.05.

# Formulazione del cemento

* L'ipotesi alternativa è ciò che vogliamo  dimostrare, cioè  che il cemento *doped* contiene una maggiore percentuale di calcio.

\bigskip

* Il test quindi è:

\begin{align*}
H_0: \; & \mu_{\text{standard}} \geq  \mu_{\text{doped}}\\
H_1: \; & \mu_{\text{standard}} < \mu_{\text{doped}}\\
\end{align*}



# Formulazione del cemento: dati

\begin{align*}
n_{\text{standard}} = 10\\ 
\bar{x}_{\text{standard}} = 87.0\\
s_{\text{standard}} = 5.0\\
\\
n_{\text{doped}} = 15\\
\bar{x}_{\text{doped}} = 90.0\\
s_{\text{doped}} = 4.0
\end{align*}


# Formulazione del cemento:  $s_P$

La varianza pooled è:

\bigskip

\begin{align*}
s_P^2 & = \frac{9 \cdot (5)^2 + 14 \cdot (4)^2}{10+15-2} = 19.52 \\
s_P & = \sqrt{19.52} = 4.4 \\
\end{align*}


La statistica è:


\begin{align*}
t_0 & = 
\frac{\bar{x}_{\text{standard}}-\bar{x}_{\text{doped}}}{
s_p     \sqrt{\frac{1}{n_{\text{standard}}} + \frac{1}{n_{\text{doped}}}}} \\
& = 
\frac{87 - 90}{4.4 \sqrt{\frac{1}{10} + \frac{1}{15}}} = -1.67 \\
\end{align*}




#  Regione di rifiuto


* Se $\bar{x}_{\text{doped}} > \bar{x}_{\text{standard}}$, la statistica è negativa e tende  supportare  $H_1$.

\bigskip

* In particolare, rifiutiamo  $H_0$ se $t_0 < t_{0.05,23} = -1.71$.

\bigskip

* La statistica (-1.67) è in regione di non-rifiuto: non abbiamo forte evidenza che il cemento *doped* aumenti il contenuto di calcio. 

\bigskip

# Esercizio: p - value


* La statistica è comunque vicina alla regione di rifiuto. 

\bigskip

* Usando le tavole, provate a stimare approssimativamente il valore del $p$-value.

# Esercizio: confronto fra metodi di vendita

* Si confrontano i pezzi venduti settimanalmente  di un certo prodotto in due gruppi di supermercati.

\bigskip

* I supermercati del  primo adottano la collocazione a scaffale, mentre quelli del secondo utilizzano uno spazio dedicato.

\bigskip

* Con confidenza 95%., possiamo concludere che le vendite medie nel caso dello spazio dedicato siano significativamente superiori a quelle dello scaffale?




# Dati

\begin{align*}
n_{\text{scaffale}} & =  10 \\
n_{\text{dedicato}} & =  10 \\
\\
\bar{x}_{\text{scaffale}} & =  50.3 \\
\bar{x}_{\text{dedicato}} & =  72 \\
\\
s^2_{\text{scaffale}} & =  350 \\
s^2_{\text{dedicato}} & =  157 \\
\end{align*}


# 
## Campioni appaiati

# Campioni non indipendenti (appaiati)


* A volte le osservazioni delle due popolazioni sono appaiate (*paired*)

\bigskip

* L'osservazione $i$-esima è presa in condizioni omogenee per entrambi i campioni, ma la condizione cambia ad ogni osservazione.

# Esempio di campioni appaiati

* Vogliamo comparare le misure di durezza del metallo svolte da due tipi di  punte.

\bigskip

* La macchina spinge la punta nel metallo con una forza prestabilita.  
La durezza del metallo si deduce dalla profondità del foro.

\bigskip

* Potremmo testare le due punte  su  pezzi di metallo diversi tratti dalla stessa produzione  e poi applicare il $t$-test per campioni indipendenti.

\bigskip

* Ma le differenze di misura  sarebbero dovute sia al tipo di punta sia alle piccole differenze tra i  pezzi.


#  Campioni appaiati

* È meglio  usare entrambe le punte su ogni pezzo di metallo.   

\bigskip

* I pezzi di metallo sono il fattore appaiante dei due campioni.  

\bigskip

* Misuriamo quindi la differenza di misura su ogni pezzo di metallo.


# $t$-test appaiato

* Consideriamo due campioni costituiti da $n$ osservazioni appaiate:

\bigskip

* Calcoliamo la differenza, in ogni osservazione, tra il valore del primo e del secondo campione. 

\bigskip

* Otteniamo così il campione delle differenze, che ha lunghezza $n$, media  $\bar{d}$ e deviazione standard    $s_d$.


# $t$-test appaiato

\bigskip

* Denotiamo $\mu_d = \mu_1 - \mu_2$ e facciamo questo test
sul campione delle differenze:

\begin{align*} 
H_0 \; &: \mu_d = 0 \\
H_1 \; &: \mu_d \neq 0
\end{align*}



\bigskip

* La  statistica è:

$$ t_0 = \frac{\bar{d}}{s_d/\sqrt{n}}$$
\bigskip

* la cui distribuzione campionaria è  una $t$ con n-1 gradi di libertà.


# Intervallo di confidenza

L'intervallo di confidenza è  simmetrico attorno a   $\bar{d}$ :
$$ \bar{d} \pm t_{\alpha/2,n-1} \frac{s_d}{\sqrt{n}}$$


# Misure di durezza svolte dalle due punte.

```{r, echo=FALSE, out.width = '85%', fig.align = 'center', warning=FALSE}
options(knitr.table.format = "latex")
sw    <- round( c(10,  9.9, 9.8, 10, 9.9, 10, 9.9, 10.1),1)
test  <-  seq(1, length(sw))
nuovo <- round( c(9.9, 9.9, 9.9, 9.8, 9.9, 9.8, 10.0,9.9),1)
d     <- sw - nuovo
df    <- as.data.frame( cbind(test, sw, nuovo, d))
colnames(df) <- c("metallo", "punta A", "punta B", "diff")
knitr::kable(df, booktabs = TRUE) %>%
  kable_styling(position = "center")

d_bar <- round(mean(df$diff),2)
s_d   <- round(sd(df$diff),2)
n     <- length(df$diff)
t     <-  round(d_bar / (s_d / sqrt(n)),2)
crit   <- qt(.975, df=n)
```
\bigskip


  
# Le misure medie delle due punte sono significativamente diverse?


\begin{align*}
H_0 \; &: \mu_{d} = 0 \\ 
H_1 \; &: \mu_{d} \neq 0 \\
\end{align*}

*  $\bar{d}$ = `r d_bar` 
*  $s_d$ =  `r s_d`
*  $t_0$ = `r d_bar`/ (`r s_d` / sqrt(`r n`)) = `r t`

\bigskip

* I valori critici sono: $t_{\alpha/2,7},t_{1-\alpha/2,7}$, cioè  $\pm$ `r round(crit,2)` 

\bigskip

* La statistica è in regione di *non rifiuto*. Non c'è differenza sistematica tra le misure medie dei due strumenti, anche se le misure su ogni singolo pezzo sono differenti.

# Intervallo di confidenza


```{r, include=FALSE} 
up   <-  round (d_bar + (s_d / sqrt(n)) * crit, 2)
low  <-  round (d_bar - (s_d / sqrt(n)) * crit, 2)
```

* L'intervallo di confidenza è:



$$ \bar{d} \pm t_{n-1,1-\alpha/2} \frac{s_D}{\sqrt{n}} $$ 

* i cui estremi sono [`r up`, `r low`]  

\bigskip

* Questo intervallo contiene lo 0,  coerentemente con l'esito del test precedente (test a due code e CI svolti con lo stesso $\alpha$ danno esiti coerenti).



# Esercizio

* Uno studio ha chiesto a 14 guidatori di parcheggiare due auto identiche, ma con volante di diversa dimensione.

\bigskip

* I tempi di parcheggio (espressi in secondi) mostrano una differenza media $\bar{d}$=1.21 ed una deviazione standard della differenza $s_D$=12.68.


\bigskip

* Con confidenza 90%, possiamo dire che il tempo medio di parcheggio delle due auto è significativamente diverso?



```{r child = '2proporzioni.Rmd'}
```


```{r child = 'soluzioni.Rmd'}
```

