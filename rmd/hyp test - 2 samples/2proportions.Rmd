#
## Comparing two proportions

# Hypothesis test for two proportions


* We want to check whether $\pi_1$ e $\pi_2$, the proportion of successes in two populations,
are significantly different.

\bigskip 

* We observe the *sample* proportion of successes, $p_1 = \frac{X_1}{n_1}$ and  $p_2 = \frac{X_2}{n_2}$, while $\pi_1$ and $\pi_2$ cannot be observed.

\bigskip 

* The term success and failure refer to the outcome being 1 or 0.

\bigskip 

* If both samples contains at least 5 successes and failures, then  $p_1$ and  $p_2$ are approximately normally distributed. We use this approximation in order to define the sampling distribution of the statistic.


# Comparing two proportions

* We have two samples of size $n_1$ e $n_2$, containing $X_1$ and $X_2$    successes.

\bigskip

* The two-tailed test is:

\begin{align*}
H_0 \; & : \pi_1 = \pi_2 \\
H_1 \; & : \pi_1 \neq \pi_2
\end{align*}

# The test statistic


\begin{align*}
Z & = \frac{(p_1 - p_2)}{\sqrt{\bar{p}(1-\bar{p}) \left( \frac{1}{n_1} + \frac{1}{n_2} \right)}} \\
& \text{with :}\\
\\
\bar{p} & = \frac{X_1 + X_2}{n_1 + n_2}\\
\end{align*}


* Under $H_0$, the statistic  $Z \sim N(0,1)$

# The test statistic

* If we extract many times two samples of size $n_1$ and $n_2$ from two populations with
  $\pi_1 = \pi_2$ and compute the statistic, it will be different every time, following 
  approximately a  $N(0,1)$ distribution.

\bigskip

* It the test is one-tailed the statistics remains the same, but the rejection region changes.

# Rejection regions

|  $H_1$                    |             Rejection region            |       p-value       |   |
|:-------------------------:|:-----------------------------------------:|:-------------------:|---|
|     $\pi_1 \neq \pi_2$    | $z < z_{\alpha/2}$ e $z > z_{1-\alpha/2}$ | $2 (1-\Phi(|z|))$ |   |
|      $\pi_1 > \pi_2$      |             $z > z_{1-\alpha}$            |     $1-\Phi(z)$     |   |
|      $\pi_1 < \pi_2$      |              $z < z_{\alpha}$             |      $\Phi(z)$      |   |


# CI of $\pi_1 - \pi_2$

* If we extract many times two samples of size $n_1$ and $n_2$ from two populations with
  $\pi_1 = \pi_2$ and compute the CI, it will contain the actual value of  $\pi_1 - \pi_2$ 
  in ($1 - \alpha$) of the experiments.

* The CI is:

\[
p_1 - p_2 \pm z_{1-\alpha/2} \sqrt{ \frac{p_1 (1-p_1)}{n_1} + \frac{p_2 (1-p_2)}{n_2}}
\]

\bigskip 
* The CI and the two-tailed test approximate differently the standard error and they might  sometimes draw inconsistent conclusions.

# Esempio: valutare l'efficacia di un farmaco

* Per valutare l'efficacia di un farmaco si svolge un *randomized trial*.

\bigskip

* In modo casuale ad alcuni pazienti viene somministrato il farmaco; ad altri il placebo.

\bigskip

* Alla fine del periodo di cura, è necessario analizzare se c'è una differenza statisticamente significativa fra i due gruppi.

# Example: assess the effect of a process innovation

* From a traditional production process we have 262 boards, of which 154 without any defect.

\bigskip

* From a innovative production process we have 227 boards, of which 163 without any defect.

\bigskip

* Is the new process significantly more accurate than the previous one?


# Comparing the two proportions

* Both samples contain more than 5 successes and 5 failures; the normal approximation is sound.

\bigskip

* The  test is:

\begin{align*}
H_0 \; : \pi_{\text{farmaco}} \leq \pi_{\text{placebo}}\\
H_1 \; : \pi_{\text{farmaco}} > \pi_{\text{placebo}}\\
\end{align*}

* and we use  $\alpha=0.01$.

# Comparing the two proportions

* The rejection region contains positive values  of $p_{\text{farmaco}} - p_{\text{placebo}}$ and thus also of the  statistic.

\bigskip

* Rejection region: $Z_0 > \Phi^{-1}({.99})$ = `r round(qnorm(.99),2)`

# Comparing the two proportions

```{r, echo=FALSE, out.width = '85%', fig.align = 'center', warning=FALSE}

n1 <- 227
n2 <- 262
p1 <- 163/n1
p2 <- 154/n2
p_bar  <- (163 + 154) / (n1 + n2)
p_err <- sqrt ( (p_bar * (1 - p_bar)) * (1/n1 + 1/n2) )
p_stat <- (p1 - p2) / p_err
p_stat <- round(p_stat,2)
p_val  <-  1 - pnorm(p_stat)
```


\bigskip 

\begin{align*}
p_{\text{new}} & = 163/227 = 0.72 \\
p_{\text{old}} & = 154/262 = 0.59 \\
\bar{p} & = (163 + 154)/(227 + 262) = 0.65\\
Z & = \frac{p_{\text{new}} - p_{\text{old}}} 
{\sqrt{ \bar{p} \cdot (1-\bar{p}) \cdot 1/n}} = 3.01 > 2.33\\
\end{align*}


\bigskip
* The statistic is in rejection region.


# Esercizio

* Un processo produce cuscinetti per l'albero motore.

\bigskip

* Si preleva un campione di 85 cuscinetti, che risulta contenere 12 non-conformi.

\bigskip

* Il processo produttivo viene quindi rivisto. Si preleva un nuovo campione di 85 cuscinetti, che risulta contenere 8 non-conformi.

\bigskip

* Possiamo concludere con confidenza del 95% che la frazione di non-conformi è significativamente decresciuta?