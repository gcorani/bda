{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Week 2: Probability, Bayes' Theorem, Continuous random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A group of researchers has designed a new inexpensive and\n",
    "painless test for detecting lung cancer. The test is intended to be an initial screening\n",
    "test for general population. A positive result (presence of lung cancer)\n",
    "from the test would be followed up immediately with medication, surgery or more\n",
    "extensive and expensive test. The researchers know from their studies the following\n",
    "facts:\n",
    "\n",
    "* The test gives a positive result in 98% of the cases when the subject has lung\n",
    "cancer.\n",
    "* The test gives a negative result in 96 % of the cases when the subject does\n",
    "*not* have lung cancer.\n",
    "* In the general population, approximately one person in 1000 has lung cancer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The random variables are:\n",
    "\\begin{align}\n",
    "&H \\text{ (health status) } \\text{ with values } \\mathbb{H}=\\{h, c\\} \\\\\n",
    "&T \\text{ (test outcome) } \\text{with values } \\mathbb{T}=\\{neg, pos\\} \n",
    "\\end{align}\n",
    "\n",
    "The random variable $H$ (health status) has possible states: c (cancer), h (healthy). <br/> \n",
    "The random variable $T$ (test outcome) has possible states: pos (positive), neg (negative)<br/> \n",
    "Positive here means \"Lung cancer detected\"\n",
    "\n",
    "The available information can be summarized as:\n",
    "\\begin{align}\n",
    "P(c) &= 1\\cdot 10^{-3} \\\\\n",
    "P(pos|c) &= 0.98 \\\\\n",
    "P(neg|h) &= 0.96\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_c = 1e-3 # probability of lug cancer p(c) (prevalence of the disease)\n",
    "p_pos_st_c = 0.98 # p(pos|c), prob of pos such that c\n",
    "p_neg_st_h = 0.96 # p(neg|h), prob of neg such that h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compute $P(h), P(neg|c), P(pos|h)$. \n",
    "\n",
    "    Hint: probabilities sum up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P(h) &= 1 - P(c)\\\\\n",
    "P(neg|c) &= 1 - P(pos|c) \\\\\n",
    "P(pos|h) &= 1 - P(pos|h)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_h = 1-p_c\n",
    "p_neg_st_c = 1-p_pos_st_c\n",
    "p_pos_st_h = 1-p_neg_st_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compute $P(c, pos), P(h, pos), P(c, neg), P(h, neg)$. \n",
    "\n",
    "    Hint: see definition of joint probability, slide 27 Lecture 2: Bayes' rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P(c, pos) &= P(c) P(pos | c)\\\\\n",
    "P(h, pos) &= P(h) P(pos | h) \\\\\n",
    "P(c, neg) &= P(c) P(neg | c) \\\\\n",
    "P(h, neg) &= P(h) P(neg | c) \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_c_and_pos = p_c * p_pos_st_c\n",
    "p_h_and_pos = p_h * p_pos_st_h\n",
    "p_c_and_neg = p_c * p_neg_st_c\n",
    "p_h_and_neg = p_h * p_neg_st_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# software note: the joint distribution can be represented as a 2D object (matrix, dataframe)\n",
    "X = [[p_c_and_pos, p_c_and_neg],\n",
    "     [p_h_and_pos, p_h_and_neg]\n",
    "    ]\n",
    "df_p = pd.DataFrame(X, columns=[\"pos\", \"neg\"], index=[\"c\", \"h\"])\n",
    "df_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compute $P(pos)$ and $P(neg)$.\n",
    "\n",
    "    Hints:\n",
    "\n",
    "    * you already have the joint from previous bullet point and want a marginal. You can use the formulas at slide 34 (or 35) of Lecture 2: Bayes' rule.\n",
    "\n",
    "    * very similar computation (for Covid test) at slide 42 of Lecture 2: Bayes' rule.\n",
    "\n",
    "    * probabilities sum up to one. Once you compute $p(pos)$, $p(neg)$ is very easy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$ P(pos) = \\sum_{x \\in \\mathbb{H}} P(x, pos) = P(c, pos) + P(h, pos) = P(h)P(pos|h) + P(c)P(pos|c) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_pos = p_c_and_pos + p_h_and_pos #p_h * p_pos_st_h + p_c * p_pos_st_c\n",
    "p_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_neg = 1-p_pos #p_c_and_neg + p_h_and_neg\n",
    "p_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compute $P(c|pos)$ and $P(h|pos)$. Comment the results\n",
    "\n",
    "    Hints:\n",
    "    * time to apply Bayes' theorem, slide 23 of Lecture 2: Bayes' rule\n",
    "    * you have already computed numerator/denominator in the previous bullet points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "According to Bayes' theorem:\n",
    "$$P(c|pos) = \\frac{P(c)P(pos|c)}{P(pos)} = \\frac{P(c, pos)}{P(pos)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_c_st_pos = p_c * p_pos_st_c / p_pos # p_c_and_pos / p_pos\n",
    "p_c_st_pos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_h_st_pos = 1-p_c_st_pos\n",
    "p_h_st_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We observe that a positive test increases the probability of having lung cancer by a factor 24x:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_c_st_pos/p_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, the probability of lung cancer after a positive test is still relatively low (about 2.4%). If we plan to test the whole population with this method, we should be ready to expect a large number of false positives!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compute $P(c|neg)$ and $P(h|neg)$. Comment the results.\n",
    "\n",
    "    Hints:\n",
    "    * Use again Bayes' theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_c_st_neg = p_c * p_neg_st_c / p_neg # p_c_and_pos / p_pos\n",
    "p_c_st_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_h_st_neg = 1-p_c_st_neg\n",
    "p_h_st_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c/p_c_st_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of having lung cancer after a negative test decreases by a factor 48x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " We have three boxes, $a$, $b$, and $c$. There are:\n",
    "* 2 red balls and 5 white balls in the box $a$\n",
    "* 4 red balls and 1 white ball in the box $b$\n",
    "* 1 red ball and 3 white balls in the box $c$.\n",
    "\n",
    "\n",
    "Consider a random experiment in which one of the boxes is randomly selected and\n",
    "from that box, one ball is randomly picked up. After observing the color of the\n",
    "ball it is replaced in the box it came from. Suppose also that on average box $a$ is\n",
    "selected 40% of the time and box $b$ 10% of the time (i.e. $P(a) = 0.4, P(b)=0.1$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_a = 0.4 # probability of picking up box a\n",
    "p_b = 0.1 # probability of picking up box b\n",
    "balls = np.array([[2, 5], [4, 1], [1, 3]]); balls # number of balls (columns in the different boxes (rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Determine the random variables and fix a notation.\n",
    "\n",
    "    Hint: take inspiration from the notation in Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random variables are:\n",
    "\\begin{align}\n",
    "B \\text{ with values } \\mathbb{B}&=\\{a, b, c\\} \\text{ (selected box) }\\\\\n",
    "C \\text{ with values } \\mathbb{C}&=\\{r, w\\} \\text{ (extracted ball color) }\n",
    "\\end{align}\n",
    "\n",
    "The random variable $B$ (selected box) has possible states: $a, b, c$. <br/> The random variable $C$ (extracted ball color) has possible states: $r$ (red), $w$ (white)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the probability of picking a red ball? Show all the passages.\n",
    "\n",
    "Numerical result: $P(r)=0.319285$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to marginalize the joint:\n",
    "$$ P(r) = \\sum_{x \\in \\mathbb{B}} P(x,r) = P(a,r) + P(b,r) + P(c,r) =  P(a)P(r|a) + P(b)P(r|b) + P(c)P(r|c)$$\n",
    "\n",
    "To apply the formula above we still need $P(c)$ and $P(r|B)= [P(r|a)\\; P(r|b)\\; P(r|c)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(c)$ is easy. We know $P(a)$, $P(b)$, and probabilities sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_c = 1 - p_a - p_b # marginal probability of box c, since probabilities sum up to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(r|B)$ may be obtained as the number of red balls in each box, divided by the number of balls in each box:\n",
    "\n",
    "\\begin{align}\n",
    "P(r|a) &= \\frac{\\# \\text{ of red balls in box a}}{\\# \\text{ of balls in box a}}\\\\ \n",
    "P(r|b) &= \\frac{\\# \\text{ of red balls in box b}}{\\# \\text{ of balls in box b}}\\\\\n",
    "P(r|c) &= \\frac{\\# \\text{ of red balls in box c}}{\\# \\text{ of balls in box c}}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_C_st_B = balls / np.sum(balls, 1).reshape(-1, 1) # a matrix representation of p(C|B)\n",
    "p_r_st_B = balls[:, 0]/np.sum(balls, 1) # a vector representation of p(r|B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_r = p_a * p_r_st_B[0] + p_b * p_r_st_B[1] + p_c * p_r_st_B[2]\n",
    "p_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If a red ball was picked, from which box it most probably came from? Show all the passages.\n",
    "\n",
    "Numerical result: the probabilities of the 3 boxes when a red ball is picked are $[0.35794183, 0.25055928, 0.39149888]$, thus box c is the most probable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the probabilities $P(B | r)$ of the different boxes $a$, $b$, $c$ conditioned on the observation that a red ball was picked.\n",
    "\n",
    "We apply Bayes' theorem:\n",
    "\n",
    "$$P(B | r) = \\frac{P(B, r)}{P(r)} = \\frac{P(B)P(r|B)}{P(r)}$$\n",
    "\n",
    "We already have the probabilities $P(B) = [P(a)\\;P(b)\\;P(c)]$ of the different boxes. We have also already computed $P(r)$ in the previous bullet point and $p(r|B)$ at an intermediate step in the previous point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_B = np.array([p_a, p_b, p_c])\n",
    "p_r_st_B = balls[:, 0]/np.sum(balls, 1) # a vector representation of p(r|B), repeated from previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_B * p_r_st_B/p_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 3 (optional)\n",
    "\n",
    "Assume that on average fraternal twins (two fertilized eggs and then could be of different sex) occur once in 100 births and identical twins (single egg divides into two separate embryos, so both have the same sex) once in\n",
    "500 births. American male singer-actor Elvis Presley (1935-1977) had a twin brother who died in birth. Assume that an equal number of boys and girls are born on average. What is the probability that Elvis was an identical twin? Show the steps how you derived the equations to compute that probability.\n",
    "\n",
    "Numerical result: 0.285714"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_frat = 1/100 # probability of fraternal twins\n",
    "p_id = 1/500 # probability of identical twins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Elvis did have a twin. We can rescale probabilities p_frat and p_id to sum up to 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_frat_e = p_frat/(p_frat + p_id)\n",
    "p_id_e = p_id/(p_frat + p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_id_and_m = p_id_e * 1\n",
    "p_frat_and_m = p_frat_e * 0.5\n",
    "p_m = p_id_and_m + p_frat_and_m\n",
    "p_id_st_m = p_id_and_m/p_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_id_st_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#p_single = 1 - p_frat - p_id # probability of a single birth\n",
    "#p_id_and_mm = p_single * 0 + p_frat*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous random variables & distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So far we have worked with discrete random variables with a finite set of possible outcomes. Throughout the course, we will work more often with continuous distributions with an infinite set of possible outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sampling from very common distribution (ex standard Gaussian, uniform) is available in `numpy.random`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "* Draw 10000 samples from a standard Gaussian distribution. Generate a histogram and a kernel density estimation plot. Comment the results.\n",
    "\n",
    "Hint: use `np.random.randn` to sample the points, `plt.hist` for the histogram, `sns.kdeplot` for the kernel density estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_samples = np.random.randn(10_000) # sample from a standard Gaussian distribution\n",
    "plt.hist(x_samples, density=True) # try density=False\n",
    "plt.xlabel(\"x\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(x_samples)\n",
    "plt.xlabel(\"x\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples are centered around 0 and span approximately the range $\\pm 3$, as expected. The empirical distribution seems indeed Gaussian. The KDE is a smooth estimate of the underlying pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    " * Compare the empirical distribution of the 1000 samples with the theoretical probability density function. \n",
    " \n",
    "Note the probability density function (pdf) of a random Gaussian variable $x$ is:  \n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{1}{2}x^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normal_pdf = lambda x: 1/(np.sqrt(2*np.pi))*np.exp(-1/2*x**2)\n",
    "x_range = np.arange(-4, 4, 0.01)\n",
    "plt.hist(x_samples, density=True, bins=50, label=\"Samples\")\n",
    "plt.plot(x_range, normal_pdf(x_range), label=\"pdf\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Note on scipy.stats\n",
    "\n",
    "More advanced tools for continuous distributions in `scipy.stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(-4, 4, 0.01)\n",
    "# norm=normal, pdf=probability density function\n",
    "normal_dist = stats.norm.pdf(x_range, loc=0, scale=1) # loc refers to the mean, scale to the standard deviation\n",
    "normal_samples = stats.norm.rvs(size=10_000, loc=0, scale=1) # norm=normal, rvs=draw random samples\n",
    "plt.hist(normal_samples, density=True, bins=50, label=\"Samples\")\n",
    "plt.plot(x_range, normal_dist);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.stats` has a convenient object-oriented interface to represent random variables. Convenient to specify distribution parameters only once..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_var = stats.norm(loc=4, scale=2) # object representing the normal distribution, with mean 4 and std 2.\n",
    "# normal_var.pdf, probability density function\n",
    "# normal_var.cdf, cumulative density function\n",
    "# normal_var.rvs, draw random samples from the distribution \n",
    "# normal_var.logpdf, logarithm of pdf (often more useful than the pdf in practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(-2, 10, 0.01)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].set_title(\"Probability density function (pdf)\")\n",
    "ax[0].hist(normal_var.rvs(10_000), density=True, bins=50)\n",
    "ax[0].plot(x_range, normal_var.pdf(x_range))\n",
    "ax[1].set_title(\"Cumulative distribution function (cdf)\")\n",
    "ax[1].hist(normal_var.rvs(10_000), density=True, bins=50, cumulative=True)\n",
    "ax[1].plot(x_range, normal_var.cdf(x_range));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`scipy.stats` has support for many more random variables, such as the common beta distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "beta_var = stats.beta(a=20, b=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "theta_range = np.linspace(0, 1, 100)\n",
    "plt.hist(beta_var.rvs(10_000), density=True, bins=50, label=\"Samples\")\n",
    "plt.plot(theta_range, beta_var.pdf(theta_range), label=\"pdf\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
