{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from matplotlib import cm\n",
    "import arviz as az\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 1: Toxicity bioassay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Problem and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The length of babies follows a square root formula..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "babies = pd.read_csv('babies.csv')#.sample(20)\n",
    "babies.sample(5)\n",
    "month_obs = babies[\"Month\"].values\n",
    "length_obs = babies[\"Length\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(babies[\"Month\"], babies[\"Length\"], 'C0.', alpha=1.0)\n",
    "ax.set_ylabel(\"Length\")\n",
    "ax.set_xlabel(\"Month\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Modeling assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the probabilistic model, we make the following assumptions:\n",
    "\n",
    "1. The average of the baby length is .\n",
    "\n",
    "2. The standard deviation:\n",
    "3. The prior probability of the parameters\n",
    "4. Probabilities are independent...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 49.5\n",
    "sigma_sigma = 10\n",
    "sigma_beta = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.1: Probabilistic model\n",
    "\n",
    "* Derive and comment the full probabilistic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Putting together the probabilistic assumptions 1-3, we obtain:\n",
    "\n",
    "\\begin{align*}\n",
    "y_i &\\sim \\mathcal{N}(\\alpha + \\beta \\sqrt M_i, \\sigma)\\\\\n",
    "\\beta &\\sim \\mathcal{N}(0, \\sigma_\\beta)\\\\\n",
    "\\sigma &\\sim |\\mathcal{N}|(\\sigma_\\sigma)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Furthermore, according to assumption 4:\n",
    "\n",
    "$$f(y|\\theta) = \\prod_i f(y_i|\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2: Maximum Likelihood estimation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Derive an analytical expression of the likelihood function $\\mathcal{L}(\\theta) = f(y|\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The likelihood function $\\mathcal{L}(\\theta)$ is $P(y|\\theta)$, seen as a function of $\\theta$, with $y$ fixed to the observed outcome. <br/>Since the individual observations $y_i$ are independent, we have:\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = f(y|\\theta) = \\prod_{i=1}^N \\frac{1}{\\sigma \\sqrt{2\\pi}} \n",
    "e^{-\\frac{1}{2} \\bigg( \\frac{y_i - (\\alpha + \\beta x_i)}{\\sigma} \\bigg )^2 }  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Derive an analytical expression of the log-likelihood function $\\ell(\\theta) = \\log P(y|\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\\ell(\\theta) &= \\sum_{i=1}^N -log(\\sigma) -1/2 \\log(2\\pi) -\\frac{1}{2}\\bigg( \\frac{y_i - (\\alpha + \\beta x_i)}{\\sigma} \\bigg )^2\\\\\n",
    "&= -\\frac{N}{2} \\log (2\\pi) -N\\log \\sigma - \\frac{1}{2 \\sigma^2}\\sum_{i=1}^{N} \\big{(} y_i - (\\alpha + \\beta x_i)  \\big{)} ^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a Python function corresponding to the like-likelihood function $\\mathcal{l}(\\theta)$. You may ignore additive factors which do not depend on $\\beta, \\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(beta, sigma):\n",
    "    x = np.sqrt(babies[\"Month\"].values)\n",
    "    y = babies[\"Length\"].values    \n",
    "    y_mu = alpha + beta*x\n",
    "    N = x.shape[0]\n",
    "    log_lik = -N/2*np.log(2*np.pi) - N*np.log(sigma) -1/(2*sigma**2) * np.sum((y - y_mu)**2)\n",
    "    return log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbeta = 0.002\n",
    "dsigma = 0.002\n",
    "\n",
    "BETA = np.arange(7.1, 7.5, dbeta)\n",
    "SIGMA = np.arange(2.6, 3.5, dsigma)\n",
    "BB, SS = np.meshgrid(BETA, SIGMA, indexing='xy')\n",
    "BBSS = np.stack((BB, SS), axis=-1)\n",
    "\n",
    "LL = np.empty((SIGMA.shape[0], BETA.shape[0]))\n",
    "for i in range(SIGMA.shape[0]):\n",
    "    for j in range(BETA.shape[0]):\n",
    "        LL[i, j] = log_lik(BETA[j], SIGMA[i])\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "c = ax.pcolormesh(BB, SS, LL, cmap=cm.coolwarm, shading='auto')\n",
    "\n",
    "fig.colorbar(c, ax=ax)\n",
    "ax.set_title(f\"Log-likelihood\");\n",
    "ax.set_xlabel(r\"$\\beta$\");\n",
    "ax.set_ylabel(r\"$\\sigma$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "log_lik_theta = lambda theta: log_lik(theta[0], theta[1])\n",
    "nll_theta = lambda theta: -log_lik_theta(theta) # negative log-likelihood function.\n",
    "res = minimize(nll_theta, x0=[7, 2])\n",
    "theta_ml = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the log-likelihood together with the maximum likelihood estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "c = ax.pcolormesh(BB, SS, LL, cmap=cm.coolwarm, shading='auto')\n",
    "plt.plot(theta_ml[0], theta_ml[1], \"kx\")\n",
    "fig.colorbar(c, ax=ax)\n",
    "ax.set_title(f\"Scaled log-likelihood\");\n",
    "ax.set_xlabel(r\"$\\beta$\");\n",
    "ax.set_ylabel(r\"$\\sigma$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the likelihood function up to a normalization constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIK_SC = np.exp(LL - np.max(LL))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "c = ax.pcolormesh(BB, SS, LIK_SC, cmap=cm.coolwarm, shading='auto')\n",
    "plt.plot(theta_ml[0], theta_ml[1], \"kx\")\n",
    "fig.colorbar(c, ax=ax)\n",
    "ax.set_title(f\"Scaled likelihood\");\n",
    "ax.set_xlabel(r\"$\\beta$\");\n",
    "ax.set_ylabel(r\"$\\sigma$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2: Maximum A Posteriori Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Derive an analytical expression of the posterior $f(\\theta | y)$, up to a multiplicative factor not depending on $\\theta$. \n",
    "\n",
    "Hint: exploit the already-obtained likelihood and the functional form of the Gaussian pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(\\theta | y) = \\frac{P(y | \\theta) f(\\theta)}{P(y)} \\propto \\mathcal{L}(\\theta)\n",
    "\\exp\\left(-\\frac{1}{2} \\frac{\\beta^2}{\\sigma^2_\\beta} \\right )\n",
    "\\exp\\left(-\\frac{1}{2} \\frac{\\sigma^2}{\\sigma^2_\\sigma} \\right ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Derive an analytical expression of the log-posterior $\\log f(\\theta | y)$, up to an additive factor not depending on $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$\\log f(\\theta | y) = \\log \\frac{P(y | \\theta) f(\\theta)}{P(y)} = \\log P(y | \\theta) + \\log f(\\beta) + \\log f(\\sigma) - \\log P(y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, \n",
    "\n",
    "$$\\log f(\\theta | y) = \\ell(\\theta) -\\frac{1}{2} \\frac{\\beta^2}{\\sigma_\\beta^2} -\\frac{1}{2} \\frac{\\sigma^2}{\\sigma_\\sigma^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Write the unnormalized posterior and log-posterior (up to a multiplicative/additive factor, respectively) as Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_post_unscaled(beta, sigma):\n",
    "    sigma_beta = 10\n",
    "    sigma_sigma = 10\n",
    "    log_lik_val = log_lik(beta, sigma)\n",
    "    return log_lik_val -0.5*beta**2/sigma_beta**2 -0.5* sigma**2/sigma_sigma**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compute the maximum a posteriore estimate $\\alpha^{\\rm MAP}, \\beta^{\\rm MAP}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "minus_logpost = lambda theta: -log_post_unscaled(theta[0], theta[1])\n",
    "res = minimize(minus_logpost, x0=[7, 2])\n",
    "theta_map = res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Visualize the MAP estimate together with the unnormalized posterior in 2D. Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LP_UNSC = np.empty((SIGMA.shape[0], BETA.shape[0]))\n",
    "for i in range(SIGMA.shape[0]):\n",
    "    for j in range(BETA.shape[0]):\n",
    "        LP_UNSC[i, j] = log_post_unscaled(BETA[j], SIGMA[i])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "c = ax.pcolormesh(BETA, SIGMA, LP_UNSC, cmap=cm.coolwarm, shading='auto')\n",
    "plt.plot(theta_ml[0], theta_ml[1], \"kx\")\n",
    "plt.plot(theta_map[0], theta_map[1], \"ko\")\n",
    "fig.colorbar(c, ax=ax)\n",
    "ax.set_title(f\"Unnormalized posterior\");\n",
    "ax.set_xlabel(r\"$\\beta$\");\n",
    "ax.set_ylabel(r\"$\\sigma$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(POST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.3 Brute-force posterior estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compute a gridding approximation of the *normalized* posterior, with the correct normalization constant. Explain the passages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have:\n",
    "    $$ \\tilde f(\\theta | y) = \\mathcal{L}(\\theta) \\exp\\left(-\\frac{1}{2} \n",
    "(\\theta - \\mu)^{\\top} \\Sigma_0^{-1} (\\theta - \\mu)^{\\top} \\right) = Z f(\\theta | y),$$\n",
    "where $Z$ is the to-be-determined normalization constant and it must be chosen such that:\n",
    "$$\\iint f(\\theta | y) d\\alpha\\; d\\beta = 1.$$\n",
    "Thus,\n",
    "$$Z = \\iint f(\\theta | y) d\\alpha\\; d\\beta.$$\n",
    "\n",
    "The integral above is intractable, but a gridding approximation may be used. Using an equi-spaced gridding, a Riemann Sum approximation is:\n",
    "\n",
    "$$Z \\approx \\Delta \\alpha \\Delta \\beta \\sum_i f(\\theta_i | y),$$\n",
    "\n",
    "where $\\Delta \\alpha$ and $\\Delta \\beta$ are the discretization steps of the 2D grid and $\\theta_i$ are the grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "POST_UNSC = np.exp(LP_UNSC - logsumexp(LP_UNSC))\n",
    "POST_SC = POST_UNSC / (dbeta * dsigma)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "c = ax.pcolormesh(BETA, SIGMA, POST_SC, cmap=cm.coolwarm, shading='auto')\n",
    "plt.plot(theta_ml[0], theta_ml[1], \"kx\")\n",
    "plt.plot(theta_map[0], theta_map[1], \"ko\")\n",
    "fig.colorbar(c, ax=ax)\n",
    "ax.set_title(f\"Normalized posterior\");\n",
    "ax.set_xlabel(r\"$\\beta$\");\n",
    "ax.set_ylabel(r\"$\\sigma$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Using the grid-based approximation of the posterior, compute the posterior mean of $\\alpha$ and $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By definition, we have:\n",
    "\n",
    "$$E[\\theta] = \\iint \\theta p(\\theta | y) d\\alpha\\; d\\beta.$$\n",
    "\n",
    "Using the grid-based approximation above:\n",
    "\n",
    "$$E[\\theta] = \\Delta \\alpha \\Delta \\beta \\sum \\theta_i p(\\theta_i | y).$$\n",
    "\n",
    "Software implementation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "beta_mean = np.sum(BB*POST_SC)*dbeta*dsigma\n",
    "sigma_mean = np.sum(SS*POST_SC)*dbeta*dsigma\n",
    "beta_mean, sigma_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is (yet another!) meaningful point estimate of $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.4 Monte-carlo estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Obtain a sample-based approximation of the posterior $f(\\theta | y)$ by implementing the Metropolis algorithm from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def p_ratio_fun(beta_propose, sigma_propose, beta_previous, sigma_previous):\n",
    "    log_p_previous = log_post_unscaled(beta_previous, sigma_previous)\n",
    "    log_p_propose = log_post_unscaled(beta_propose, sigma_propose)\n",
    "    log_p_ratio = log_p_propose - log_p_previous # log(p_prop/p_prev) = log(p_prop) - log(p_prev)\n",
    "    p_ratio = np.exp(log_p_ratio)\n",
    "    return p_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p_ratio_fun(beta_propose = 1.89, sigma_propose = 0.374, beta_previous = 24.76, sigma_previous = 20.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us run a Metropolis algorithm to sample from the posterior. The `p_ratio_fun` function is all we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "N = 100_000 # number of Metropolis steps\n",
    "beta_0 = 7.0 # initial value for alpha\n",
    "sigma_0 = 3.0 # initial value for alpha\n",
    "\n",
    "beta_step = beta_0\n",
    "sigma_step = sigma_0\n",
    "\n",
    "sigma_prop_beta = 0.1\n",
    "sigma_prop_sigma = 0.1\n",
    "\n",
    "betas = []\n",
    "sigmas = []\n",
    "for idx in range(N):\n",
    "    betas.append(beta_step)\n",
    "    sigmas.append(sigma_step)\n",
    "\n",
    "    beta_prop = beta_step + sigma_prop_beta * np.random.randn()\n",
    "    sigma_prop = sigma_step + sigma_prop_sigma * np.random.randn()\n",
    "    \n",
    "    p_ratio = p_ratio_fun(beta_prop, sigma_prop, beta_step, sigma_step)\n",
    "    accept_prob = np.minimum(1.0, p_ratio)\n",
    "    accept = (np.random.rand() < accept_prob)\n",
    "    \n",
    "    if accept:\n",
    "        beta_step = beta_prop\n",
    "        sigma_step = sigma_prop\n",
    "\n",
    "betas = np.stack(betas)\n",
    "sigmas = np.stack(sigmas)\n",
    "thetas = np.c_[betas, sigmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(betas, sigmas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
