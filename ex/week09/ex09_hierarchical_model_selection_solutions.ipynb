{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import pandas as pd\n",
    "#import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Factory data\n",
    "\n",
    "The following dataset contains quality control measurements from 6\n",
    "machines in a factory (range: 0-120, units of the measurements are irrelevant here). \n",
    "\n",
    "In the dataset, each column contains the measurements for a single machine. Quality control measurements are expensive and time-consuming, so only 5 measurements were done for each machine. \n",
    "\n",
    "In addition to the existing machines, we are interested in the quality of another machine (the seventh machine) which is not in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_wide = pd.read_csv(\"factory.csv\")\n",
    "df_wide.set_index(\"measurement\", inplace=True)\n",
    "df_wide.columns.name = \"machine\"\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform the dataset to the long format: one row per machine per measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A \"long\" format is more convenient for the following analyises. Let us *melt* the dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.melt(df_wide.reset_index(),\n",
    "             id_vars=[\"measurement\"],\n",
    "             value_vars=['M1', 'M2', 'M3', 'M4', 'M5', 'M6'],\n",
    "             value_name='quality')\n",
    "df[\"machine\"] = df[\"machine\"].astype(\"category\") # useful for group analysis (with pymc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the category column has the useful properies `cat.categories` (all the possible values of the categorical variable) and `cat.codes` (an equivalent integer representation of the variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"machine\"].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"machine\"].cat.codes.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Some traditional data analysis (data-challenge style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Obtain the global mean and standard deviation of the quality measurement (pooled mean/standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"quality\"].mean(), df[\"quality\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Plot a histogram and a boxplot of the quality measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(df[\"quality\"]);\n",
    "#px.histogram(df[\"quality\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[\"quality\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Obtain the mean and standard deviation of quality measurement, for the different machines (unpooled mean/standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(\"machine\")[[\"quality\"]].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Draw boxplots of quality for the different factories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=df, x=\"quality\", y=\"machine\");\n",
    "#px.box(df, x=\"quality\", y=\"machine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Even from a classical analysis, there seems to be evidence that different machines have different quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pooled Bayesian Model\n",
    "\n",
    "Consider the following *pooled* Bayesian model:\n",
    "\\begin{align*}\n",
    "\\mu &\\sim N(90, 10) \\\\\n",
    "\\sigma &\\sim \\text{HalfNormal}(36) \\\\\n",
    "\\vec{y}_{ij} &\\sim N(\\mu, \\sigma) \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the pooled model and its underlying hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not make distinction between different machines. It is a single normal-normal model for measurements from all the different machines; it assumes the measurement to share *global* mean and standard deviation $\\mu$ and $\\sigma$, respectively. \n",
    "\n",
    "It could have been constructed assuming that: \n",
    "1. The (global) mean quality $\\mu$ is between $90-3*10=60$ and $90+3*10=120$ with probability 99%\n",
    "2. All quality measurements $\\vec{y}_{ij}$ is in a range of width $25*6=150$ with probability 99%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(stats.halfnorm.rvs(size=10_000, scale=36)).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the pooled model in pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model_pooled:\n",
    "    global_mu = pm.Normal('global_mu', mu=90, sigma=15)\n",
    "    global_sigma = pm.HalfNormal('global_sigma', sigma=30)\n",
    "    y = pm.Normal('y', mu=global_mu, sigma=global_sigma, observed=df[\"quality\"])\n",
    "    trace_pooled = pm.sample(10_000, idata_kwargs = {'log_likelihood': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with model_pooled:\n",
    "    display(az.summary(trace_pooled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with model_pooled:\n",
    "    az.plot_posterior(trace_pooled);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Unpooled Bayesian Model\n",
    "\n",
    "Consider the following Bayesian unpooled model\n",
    "\\begin{align*}\n",
    "\\mu_{j} &\\sim {N}(90, 20) \\\\\n",
    "\\sigma_{j} &\\sim \\text{HalfNormal}(23) \\\\\n",
    "\\vec{y}_{ij} &\\sim {N}(\\mu_j, \\sigma_j) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the unpooled model and its underlying hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unpooled model actually consists in 6 completely separate normal-normal sub-models for the 6 different machines. \n",
    "It could have build according to the hipotheses that: \n",
    "1. The mean quality of each machine is between $90-3*20=30$ and $90+3*20=150$ with probability 99%\n",
    "2. The quality measurements of each machine are in a range of width $15*6=90$ with probability 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(stats.halfnorm.rvs(size=10_000, scale=23)).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the unpooled model in pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"machine_id\"] = df[\"machine\"].cat.codes\n",
    "machines = list(df[\"machine\"].cat.categories)\n",
    "n_machines = len(machines) # number of machines (6)\n",
    "machines, n_machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model_unpooled:\n",
    "    group_mu = pm.Normal('group_mu', mu=90, sigma=20, shape=n_machines)\n",
    "    group_sigma = pm.HalfNormal('group_sigma', sigma=23, shape=n_machines)\n",
    "    #y = pm.Normal('y', mu=group_mu[df[\"machine_id\"]], sd=group_sigma[df[\"machine_id\"]], observed=df[\"quality\"])\n",
    "    y = pm.Normal('y', mu=group_mu[df[\"machine\"].cat.codes],\n",
    "                       sigma=group_sigma[df[\"machine\"].cat.codes],\n",
    "                       observed=df[\"quality\"])\n",
    "    trace_unpooled = pm.sample(10_000, idata_kwargs = {'log_likelihood': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model_unpooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_unpooled.posterior = trace_unpooled.posterior.assign_coords(group_mu_dim_0=machines,\n",
    "                                                                  group_sigma_dim_0=machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_unpooled:\n",
    "    display(az.summary(trace_unpooled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with model_unpooled:\n",
    "    axes = az.plot_forest (trace_unpooled,  kind='ridgeplot', hdi_prob=0.95, var_names=\"group_mu\", combined=True);\n",
    "    plt.title(\"Posterior mean for the 6 machines\")\n",
    "    #axes[0].set_yticklabels(machines[::-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with model_unpooled:\n",
    "    axes = az.plot_forest (trace_unpooled,  kind='ridgeplot', hdi_prob=0.95, var_names=\"group_sigma\", combined=True);\n",
    "    plt.title(\"Posterior standard deviation for the 6 machines\")\n",
    "    #axes[0].set_yticklabels(machines[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Compare the sample unpooled standard deviation with the bayesian estimate. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We already computed the sample standard deviations before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(\"machine\")[[\"quality\"]].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The posterior means of the bayesian estimates are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with model_unpooled:\n",
    "    display(az.summary(trace_unpooled, var_names=[\"group_sigma\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# az.plot_posterior(trace_separate[\"group_std\"][:, 0], point_estimate='mode')\n",
    "with model_unpooled:\n",
    "    az.plot_posterior(trace_unpooled, var_names=[\"group_sigma\"], point_estimate='mode'); # the posterior mean is 29, the mode is 19!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The sample std is rather different from the posterior std mean. The sample std is actually much similar to the posterior mode (as expected from theory)! The posterior std distributions are heavily right-skewed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hierarchical model, common std\n",
    "\n",
    "Consider the following Bayesian hierarchical model:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mu_\\mu & \\sim N(90, 10)\\\\\n",
    "\\sigma_\\mu  & \\sim \\text{HalfNormal}(30) \\\\\n",
    "\\mu_{j} &\\sim {N}(\\mu_\\mu, \\sigma_\\mu) \\\\\n",
    "\\sigma &\\sim \\text{HalfNormal}(23) \\\\\n",
    "\\vec{y}_{ij} &\\sim {N}(\\mu_j, \\sigma) \\\\\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the hierarchical model and its underlying hypotheses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hierarchical model may be seen as an extension of the unpooled model. While in the unpooled model the 6 different $\\mu_j$ are independent of each other, in the hierarchical model they share common parent variabes $\\mu_\\mu$ and $\\sigma_\\mu$ representing our prior belief about their mean value and their spread, respectively. Indeed, each $\\mu_j$ is assumed to be normal with mean $\\mu_\\mu$ and standard deviation $\\sigma_\\mu$. Furthermore, we assume a single random variable $\\sigma$ modeling the spread of the different measurements for a given machine (note that in the previous unpooled model we had different standard deviation parameters for the different groups, it is kind of an arbitrary choice/modeling assumption).\n",
    "\n",
    "From the numerical values of the model coefficients, the modeler might have made the following assumptions:\n",
    "1. The mean of the mean quality of each machine is between $90-3*10=60$ and $90+3*10=120$ with probability 99% $\\Rightarrow$ from $\\mu_\\mu \\sim N(90, 10)$\n",
    "2. The quality measurements of each machine are in a range of width $15*6=90$ with probability 99% $\\Rightarrow$ from $\\sigma \\sim \\text{HalfNormal}(23)$\n",
    "3. The different $\\mu_j$ vary in a range of width $6*20=120$ with probability 99% $\\Rightarrow$ from $\\sigma_\\mu  \\sim \\text{HalfNormal}(30)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(stats.halfnorm.rvs(size=10_000, scale=23)).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(stats.halfnorm.rvs(size=10_000, scale=30)).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implement the hierarchical model in pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model_hierarchical:\n",
    "    \n",
    "    # hyper_priors\n",
    "    mu_mu = pm.Normal('mu_mu', mu=90, sigma=10)\n",
    "    sigma_mu = pm.HalfNormal('sigma_mu', sigma=30)\n",
    "\n",
    "    # priors    \n",
    "    group_mu = pm.Normal('group_mu', mu=mu_mu, sigma=sigma_mu, shape=n_machines)\n",
    "    global_std = pm.HalfNormal('global_std', sigma=23)\n",
    "    y = pm.Normal('y', mu=group_mu[df[\"machine_id\"]],\n",
    "                       sigma=global_std, observed=df[\"quality\"])\n",
    "    trace_hierarchical = pm.sample(10_000, idata_kwargs = {'log_likelihood': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model_hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_hierarchical.posterior = trace_hierarchical.posterior.assign_coords(group_mu_dim_0=machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "az.summary(trace_hierarchical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection \n",
    "\n",
    "What is the best model ultimately? In our case: Pooled, Unpooled, or Hierarchical?\n",
    "\n",
    "\n",
    "To answer this question, we need a **model selection** strategy/metric.\n",
    "\n",
    "* You know metrics for point regression models (mse, rmse, mae,...)\n",
    "* You know metrics for point classification models (accuracy, prediciton, recall...)\n",
    "\n",
    "\n",
    "### The WAIC Criterion \n",
    "To score full Bayesian models, we need a metric that evaluates a (sample-based approximation of a) *distribution*. \n",
    "\n",
    "* A popular metric to score a distribution is the log-pointwise-predictive-density ${\\rm lpd}(y, \\Theta)$:\n",
    "$$ {\\rm lpd}(y, \\Theta) = \\sum_i \\log \\frac{1}{S} \\sum_s p(y_i | \\Theta_s),$$\n",
    "where $y$ are the observations and $\\Theta$ is the sample-based approximation of the posterior ($\\Theta_s$ is a single MCMC draw). It is the (approximate) logarithm of the expected likelihood (the higher, the better)!\n",
    "\n",
    "\n",
    "* The ${\\rm lpd}(y, \\Theta)$ generally increases for increasing model complexity and it is thus prone to overfitting when used on the same data used for model building. It should be evaluated with fresh data in (cross)-validation.\n",
    "\n",
    "* The WAIC criterion (the lower, the better) balances high ${\\rm lpd}$ and low model complexity explicitly. It can be applied directly on the training data $y$!\n",
    "\n",
    "\\begin{align}\n",
    "{\\rm WAIC}(y, \\Theta) &= -2(\\rm{lpd} - p_{\\rm waic}).\\\\\n",
    " p_{{\\rm waic}} &= \\sum_i {\\rm var}_{\\theta} \\log p(y_i|\\theta)\n",
    "\\end{align}\n",
    "\n",
    "* The WAIC is equivalent up to a factor to the ${\\rm elpd}$, the *expected* $\\rm{lpd}$ on fresh data (the higher, the better):\n",
    "\n",
    "$${\\rm elpd}(y, \\Theta) = \\rm{lpd} - p_{\\rm waic}.$$\n",
    "\n",
    "Advantages of WAIC/elpd:\n",
    "\n",
    "* Well-defined both for continuous and for categorical observations\n",
    "* Applicable to Bayesian models returning point-wise estimates\n",
    "* Applicable to the training data directly (built-in complexity penalty)\n",
    "* Works well in practice\n",
    "\n",
    "Note: WAIC stands for Widely Applicable Information Criterion!\n",
    "\n",
    "### The WAIC Criterion in arviz\n",
    "\n",
    "Arviz has a built-in function `az.waic` to compute the WAIC (actually, as of v0.12.1, arviz computes the ${\\rm elpd}$, see <a href=\"https://python.arviz.org/en/v0.12.1/api/generated/arviz.waic.html?highlight=waic\">documentation</a>):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.waic(trace_pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an even more convenient method to evaluate the criterion on several models and rank them according to the WAIC criterion (from best to worst, ascending WAIC/descending elpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#with factory_pooled, factory_separate, factory_hierarchical:\n",
    "comp_df = az.compare({\"model_pooled\": trace_pooled,\n",
    "                      \"model_unpooled\": trace_unpooled,\n",
    "                      \"model_hierarchical\": trace_hierarchical},\n",
    "                      ic=\"waic\") # ic stands for \"information criterion\"\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "az.plot_compare(comp_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior predictions of new measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given the pooled model, make a prediction for a new measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do it by adding a line in pymc3 corresponding to the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_pooled_with_pred:\n",
    "    \n",
    "    global_mu = pm.Normal('global_mu', mu=90, sigma=15)\n",
    "    global_sigma = pm.HalfNormal('global_sigma', sigma=30)\n",
    "    y = pm.Normal('y', mu=global_mu, sigma=global_sigma, observed=df[\"quality\"])\n",
    "    \n",
    "    y_pred = pm.Normal(\"y_pred\", mu=global_mu, sigma=global_sigma)\n",
    "    \n",
    "    trace_pooled_with_pred = pm.sample(10_000, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_pooled_with_pred:\n",
    "    display(az.summary(trace_pooled_with_pred)) # var_names='y_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, we can play with the trace directly. For each sampled value of global_mu and global_sigma, we sample from\n",
    "N(global_mu, global_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pooled = az.extract(trace_pooled.posterior)\n",
    "\n",
    "y_pred = np.zeros_like(post_pooled.global_mu.values)\n",
    "for idx in range(y_pred.shape[0]):\n",
    "    y_pred[idx] = scipy.stats.norm.rvs(loc=post_pooled.global_mu.values[idx],\n",
    "                                       scale=post_pooled.global_sigma.values[idx])\n",
    "    \n",
    "#y_pred = scipy.stats.norm.rvs(loc=post_pooled.global_mu.values,scale=post_pooled.global_sigma.values) # faster vectorized implementation!\n",
    "\n",
    "y_pred.mean(), y_pred.std() # similar to y_pred in the trace (note: there is randomness!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given the unpooled model, make a prediction for a new measurement of the machine M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_unpooled_with_pred_M1:\n",
    "    group_mu = pm.Normal('group_mu', mu=90, sigma=20, shape=n_machines)\n",
    "    group_sigma = pm.HalfNormal('group_sigma', sigma=23, shape=n_machines)\n",
    "    y = pm.Normal('y', mu=group_mu[df[\"machine\"].cat.codes],\n",
    "                  sigma=group_sigma[df[\"machine\"].cat.codes],\n",
    "                  observed=df[\"quality\"])\n",
    "    \n",
    "    y_M1_pred = pm.Normal('y_M1', mu=group_mu[0], sigma=group_sigma[0])\n",
    "    \n",
    "    trace_unpooled_with_pred_M1 = pm.sample(10_000, return_inferencedata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model_unpooled_with_pred_M1:\n",
    "    display(az.summary(trace_unpooled_with_pred_M1, var_names=\"y_M1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_unpooled = az.extract(trace_unpooled.posterior)\n",
    "y_M1_pred = scipy.stats.norm.rvs(loc=post_unpooled.group_mu[0].values,\n",
    "                                 scale=post_unpooled.group_sigma[0].values)\n",
    "y_M1_pred.mean(), y_M1_pred.std() # similar to y_pred in the trace (note: there is randomness!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "221c891a34d53b6a976517fba14e87e2d44925797743ab4436332eb8ae3ca627"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
