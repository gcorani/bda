{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise session 6: WAIC"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us test WAIC on the Beta-Binomial model: the *Hello World* probabilistic programming"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us consider a coin that falls heads with probability $\\theta=0.25$ (assumed unknown). \n",
    "\n",
    "Our prior knowledge of $\\theta$ is encoded in a Beta distributions with parameters $a=20$ and $b=10$:\n",
    "\n",
    "$$ p_{\\rm prior}(\\theta) = \\frac{1}{B(a,b)} \\theta^{a-1} (1-\\theta)^{b-1}, \\qquad \\theta \\in [0, 1],$$\n",
    "\n",
    "where $B(a,b)$ is a proper normalization constant such that $\\int_{0}^1 p_{\\rm prior}(\\theta) \\; d \\theta = 1.$ \n",
    "\n",
    "We toss the coin $n$ times and measure a number $y$ of heads. How does our belief of $\\theta$ change with the measurement?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = 20 # prior: parameter a\n",
    "b = 10 # prior: parameter b\n",
    "n = 50 # likelihood: number of tosses\n",
    "y = 15 # likelihood: number of HEADs observed. (Fixed in this example. It could be sampled form a binomial instead)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with pm.Model() as beta_binomial:\n",
    "    theta = pm.Beta(\"theta\", alpha=a, beta=b)\n",
    "    y_obs = pm.Binomial(\"y_obs\", n=n, p=theta, observed=y)\n",
    "    trace_bb = pm.sample(1000, random_seed=123, return_inferencedata=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with beta_binomial:\n",
    "    display(az.summary(trace_bb))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_trace(trace_bb);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "az.plot_posterior(trace_bb, color=\"b\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WAIC Definition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us denote by $\\Theta$ the samples $\\theta_0, \\theta_1, \\dots, \\theta_{S-1}$ in the trace and by $y$ the measurement(s). \n",
    "\n",
    "* The log-pointwise-predictive-density $\\rm lppd$ is defined as:\n",
    "\n",
    "$$ {\\rm lppd}(y, \\Theta) = \\sum_i \\log \\frac{1}{S} \\sum_s p(y_i | \\Theta_s),$$\n",
    "\n",
    "* The effective number of parameters $p_{{\\rm waic}}$ is defined as:\n",
    "\n",
    "$$ p_{{\\rm waic}} = \\sum_i {\\rm var}_{\\theta} \\log p(y_i|\\theta)$$\n",
    "\n",
    "* The WAIC criterion (the lower, the better) is:\n",
    "\n",
    "$${\\rm WAIC}(y, \\Theta) = -2(\\rm{lppd} - p_{\\rm waic}).$$\n",
    "\n",
    "* The expected log pointwise predictive density $\\rm{elpd}$ (the higher, the better) is defined as:\n",
    "\n",
    "$$\\rm{elpd} = (\\rm{lppd} - p_{\\rm waic}).$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WAIC computation details\n",
    "\n",
    "Let us consider a scalar observation $y$ (as in our example). In the definitions above, the outer summations on $i$ disappear. \n",
    "\n",
    "Let us denote by ``lik_vec`` and ``loglik_vec`` vectors containing, respectively, the likelihood and log-likelihood of $y$, for the samples of $\\theta_s \\in \\Theta$:\n",
    "\n",
    "$$\\text{loglik_vec} = [\\log p(y | \\theta_0)\\;\\; \\log p(y | \\theta_1),\\;\\; \\dots,\\;\\; \\log p(y | \\theta_{S-1})]^\\top$$\n",
    "$$\\text{lik_vec} = [p(y | \\theta_0)\\;\\; p(y | \\theta_1),\\;\\; \\dots,\\;\\; p(y | \\theta_{S-1})]^\\top$$\n",
    "\n",
    "* $p_{{\\rm waic}}$ can be computed as the sample variance of ``loglik_vec``. In Python:\n",
    "\n",
    "``p_waic = np.var(loglik_vec)``\n",
    "\n",
    "* ${\\rm lppd}$ could be computed (in principle) as the logarithm of the average of ``lik_vec``. In Python:\n",
    "\n",
    "``lppd = np.log(np.mean(lik_vec))``\n",
    "\n",
    "* For better numerical precision, ${\\rm lppd}$ computation is typically worked out in the log-domain, exploiting the logsumexp trick:\n",
    "\n",
    "``lppd = scipy.special.logsumexp(log_lik_vec) - np.log(S)``\n",
    "\n",
    "This exploits the identity:\n",
    "\n",
    "$$\\log {{\\sum_s p(y_i | \\theta_s)}} =  \\log\\left(\\sum_s e^{\\log p(y_i | \\theta_s)}\\right),$$\n",
    "where at the right-hand-side we recognize the ``logsumexp`` operation applied to the vector ``loglik_vec``."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WAIC Computation with arviz"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "arviz computes these quantity automatically:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with beta_binomial:\n",
    "    display(az.waic(trace_bb))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## WAIC Manual computation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Write the likelihood and the log-likelihood function of the observations in closed form. Note: for these calculations, we cannot disregard multiplicative/additive terms not depending on $\\theta$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The likelihood is:\n",
    "$$p(y | \\theta) = {{n}\\choose{y}} \\theta^{y} \\cdot (1-\\theta)^{n-y}.$$\n",
    "\n",
    "The log-likelihood is:\n",
    "$$\\log p(y | \\theta) = \\log {{n}\\choose{y}} + y \\log(\\theta) + (n-y)\\log(1-\\theta).$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Obtain the likelihood and the log-likelihood as python functions (including multiplicative/additive factors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def lik(theta):\n",
    "    return scipy.special.binom(n, y) * (theta ** y) * (1 - theta)**(n-y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def log_lik(theta):\n",
    "    return np.log(scipy.special.binom(n, y)) + y*np.log(theta) + (n-y)*np.log(1 - theta)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Extract the samples $\\Theta$ from the trace."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "theta_trace = np.array(trace_bb.posterior.theta).ravel()\n",
    "S = theta_trace.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Compute $\\rm{lppd}$ and $p_{\\rm waic}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_lik_vec = log_lik(theta_trace)\n",
    "# log_lik_pm = np.array(trace_bb.log_likelihood.y_obs).ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lppd = np.log(np.mean(lik(theta_trace)))\n",
    "lppd = scipy.special.logsumexp(log_lik_vec) - np.log(S) # sum is equivalent to logsumexp in log domain..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p_waic = np.var(log_lik_vec) # correct\n",
    "p_waic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Compute $\\rm{waic}$ and ${\\rm elpd}$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "waic = -2*(lppd - p_waic); waic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "elpd = (lppd - p_waic); elpd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}