import numpy as np
import scipy
import scipy.stats as stats
import matplotlib.pyplot as plt
import pymc as pm
import arviz as az
import seaborn as sns


sns.set()











a = 20 # prior: parameter a
b = 10 # prior: parameter b
n = 50 # likelihood: number of tosses
y = 15 # likelihood: number of HEADs observed. (Fixed in this example. It could be sampled from a binomial instead)
#np.random.seed(42)
#y = np.random.binomial(n, theta) # random number of heads from the distribution from a binomial distribution














a_post = a + y
b_post = b + n - y
prior_var = stats.beta(a=a, b=b)
post_var = stats.beta(a=a_post, b=b_post) # closed-form expression...


prior_var.interval(.95)





dtheta = 1e-3 # discretization step for theta
theta_vec = np.arange(0, 1, dtheta) # discretized theta range
alpha = 0.05
plt.plot(theta_vec, prior_var.pdf(theta_vec), label="prior", color="C0")
prior_L, prior_H = prior_var.interval(1-alpha)
plt.axvspan(xmin=prior_L, xmax=prior_H, alpha=0.1, color="C0")
plt.plot(theta_vec, post_var.pdf(theta_vec), label="posterior", color="C1")
post_L, post_H = post_var.interval(1-alpha)
plt.axvspan(xmin=post_L, xmax=post_H, alpha=0.1, color="C1")
#plt.axvline(theta_0, color="black", label=r"true $\theta$")
plt.xlabel(r"$\theta$")
plt.legend()
plt.title(r"Prior and posterior distribution of $\theta$");

















prior_fun = lambda theta: stats.beta.pdf(theta, a, b)
lik_fun = lambda theta: (theta ** y) * (1 - theta)**(n-y)

def unnorm_prior_fun(theta):
    p_theta = theta**(a-1)*(1-theta)**(b-1) # since we look for an unnormalized posterior, this is also good enough
    p_theta = p_theta * ((theta <= 1.0) & (theta >= 0.0))
    return p_theta
    
unnorm_post_fun = lambda theta: unnorm_prior_fun(theta)*lik_fun(theta)





dtheta = 1e-3
theta_vec = np.arange(0, 1, dtheta)
plt.plot(theta_vec, unnorm_post_fun(theta_vec))
plt.xlabel(r"$\theta$");
plt.title(r"Unnormalized posterior distribution of $\theta$");





dtheta = 1e-3
theta_vec = np.arange(0, 1, dtheta)
Z = np.sum(unnorm_post_fun(theta_vec)) * dtheta
normalized_post_fun = lambda theta: unnorm_post_fun(theta)/Z





plt.plot(theta_vec, post_var.pdf(theta_vec), label="Exact")
plt.plot(theta_vec, normalized_post_fun(theta_vec), label="Normalized")
plt.xlabel(r"$\theta$");
plt.legend()
plt.title(r"Posterior distribution of $\theta$");














sigma = 0.1 # proposal standard deviation
theta_0 = 0.5 # an initial guess
N = 50_000 # chain length


theta_step = theta_0
p_step = unnorm_post_fun(theta_step)
thetas = [] # here we collect the theta values from the chain

for idx in range(N):
    thetas.append(theta_step)
    theta_prop = theta_step + sigma*np.random.randn()
    theta_prop = np.clip(theta_prop, 0, 1)
    p_prop = unnorm_post_fun(theta_prop) # evaluate unscaled distribution
  
    p_ratio = p_prop/p_step # the multiplicative factor disappears from the ratio!
    if p_ratio > 1:
        accept = True
    else:
        accept =  np.random.binomial(1, p_ratio) # othewise, accept w.p. p_ratio
        #accept = scipy.stats.bernoulli(p_ratio).rvs() # way slower!
    
    if accept:
        theta_step = theta_prop
        p_step = p_prop





plt.hist(thetas, density=True, bins=50, label="Metropolis samples")
plt.plot(theta_vec, post_var.pdf(theta_vec), label="Exact posterior")
plt.legend()
plt.xlim([0, 1]);








def log_lik_fun(theta):

    eps = 1e-12
    theta = np.minimum(theta, 1 - eps)
    theta = np.maximum(theta, eps)
    
    log_lik =  y * np.log(theta) + (n-y)*np.log(1 - theta)
    return log_lik

def unnorm_log_prior_fun(theta): # otherwise, use prior_dist.logpdf
    
    eps = 1e-12
    theta = np.minimum(theta, 1 - eps)
    theta = np.maximum(theta, eps)

    log_f_theta = (a-1)*np.log(theta) + (b-1)*np.log(1-theta) 
    log_f_theta = log_f_theta * ((theta <= 1.0) & (theta >= 0.0))
    return log_f_theta

unnorm_log_post_fun = lambda theta: log_lik_fun(theta) + unnorm_log_prior_fun(theta)


dtheta = 1e-3
theta_vec = np.arange(0, 1, dtheta)
plt.plot(theta_vec, unnorm_log_post_fun(theta_vec))
plt.xlabel(r"$\theta$");
plt.title(r"Unnormalized log-posterior  distribution of $\theta$");














def f_ratio_fun(theta_propose, theta_current):
       
    log_f_propose = unnorm_log_post_fun(theta_propose)
    log_f_current = unnorm_log_post_fun(theta_current)
    log_f_ratio = log_f_propose - log_f_current # log(p_prop/p_prev) = log(p_prop) - log(p_prev)
    f_ratio = np.exp(log_f_ratio)
    #f_ratio = np.nan_to_num(p_ratio, nan=0.0)
    return f_ratio





theta_step = theta_0
thetas = [] # here we collect the theta values from the chain

for idx in range(N):
    thetas.append(theta_step)
    theta_prop = theta_step + sigma*np.random.randn()
    theta_prop = np.clip(theta_prop, 0, 1)
    
    f_ratio = f_ratio_fun(theta_prop, theta_step)
    accept_prob = np.minimum(1.0, f_ratio)
    accept = (np.random.rand() < accept_prob)
    
    if accept:
        theta_step = theta_prop


plt.hist(thetas, density=True, bins=50, label="Metropolis samples")
plt.plot(theta_vec, post_var.pdf(theta_vec), label="Exact posterior")
plt.legend()
plt.xlim([0, 1]);








sigma = 0.1 # proposal standard deviation
theta_0 = 0.5 # a lucky guess...
N = 50_000 # chain length

theta_step = theta_0
thetas_test = [] # here we collect the theta values from the chain

for idx in range(N):
    thetas.append(theta_step)
    theta_prop = theta_step + sigma*np.random.randn()
    theta_prop = np.clip(theta_prop, 0, 1)
    
    f_ratio = f_ratio_fun(theta_prop, theta_step)
    accept_prob = np.minimum(1.0, p_ratio)
    accept = (np.random.rand() < accept_prob)
    
    if accept:
        theta_step = theta_prop











# Approach 4: use pymc(3)

with pm.Model() as beta_binomial:
    theta = pm.Beta("theta", alpha=a, beta=b)
    y_obs = pm.Binomial("y_obs", n=n, p=theta, observed=y)
    trace_bb = pm.sample(10_000, random_seed=123, return_inferencedata=True)



with beta_binomial:
    display(az.summary(trace_bb))


np.mean(thetas), np.std(thetas) # comparison with hand-made metropolis


az.plot_trace(trace_bb);


az.plot_posterior(trace_bb, color="b");


az.plot_posterior(trace_bb, color="C0")
plt.plot(theta_vec, post_var.pdf(theta_vec), color="C1")
post_L, post_H = post_var.interval(1-alpha)
plt.axvspan(xmin=post_L, xmax=post_H, alpha=0.1, color="C1", label=r"HDI 95%");
