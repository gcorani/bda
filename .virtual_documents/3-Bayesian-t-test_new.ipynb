%matplotlib inline
import numpy as np
import pymc as pm
import pandas as pd
import matplotlib.pyplot as plt
import scipy.stats as stats
import arviz as az
import seaborn as sns
sns.set(rc={'figure.figsize':(12,8)})
sns.set_theme()

from IPython.display import display, Markdown
az.style.use('arviz-darkgrid')
np.random.seed(44)


















iq_drug = np.array ([101,100,102,104,105,97,105,105,98,101,100,123,105,103,100,95,102,106,
        109,102,82,102,100,104,102,101,102,102,103,103,97,97,103,101,97,104,
        96,103,124,103,103,100,101,103,104,100,101])
iq_placebo = np.array ([ 99,101,100,101,99,100,97,101,104,101,102,102,100,105,88,101,100,
           104,100,100,100,101,102,103,97,101,101,100,101,99,101,100,100,
           101,100,99,101,100,102,99,98,99])




y  = pd.DataFrame(dict(value=np.r_[iq_drug, iq_placebo], group=np.r_[['drug']*len(iq_drug), ['placebo']*len(iq_placebo)]))
sns.histplot(data=y, x="value", hue="group");























#Here we tune the half-normal prior for sigma, adjusting the scale to have the median close to 20.
from scipy.stats import halfnorm
# this yields a  diffuse prior, but still defined over plausible range. 
pd.DataFrame(halfnorm.rvs(scale=30, size=10000)).describe()












with pm.Model() as  normal_model:
    #prior
    mu_drug         = pm.Normal     ('mu_drug',  mu = 100,  sigma = 10)
    mu_placebo      = pm.Normal     ('mu_placebo', mu = 100,  sigma = 10)
    sigma_drug      = pm.HalfNormal ('sigma_drug',  sigma=30)
    sigma_placebo   = pm.HalfNormal ('sigma_placebo', sigma=30)

    
    #likelihood of group 1
    y_drug         = pm.Normal  ('y_1',  mu=mu_drug,      sigma=sigma_drug,       observed= iq_drug)
    
    #likelihood of group 2
    y_placebo   = pm.Normal  ('y_2',  mu=mu_placebo, sigma=sigma_placebo, observed= iq_placebo)
    
    #The deterministic variables are function of the parameters, whose values appear in the trace.
    diff_of_means = pm.Deterministic ('diff_of_means', mu_drug - mu_placebo)



with normal_model:
    normal_trace    = pm.sample(return_inferencedata=True)





#sampling was good. The posterior of sigma is very similar for both groups, while there are differences in  the posterior mean of the two groups.
az.plot_trace(normal_trace);


# The posterior distribution can be checked in different ways, depending on the question we want to answer.

#Possible question 1: is the hypothesis of equal means of the two populations plausible?
#In traditional hypothesis testing, this corresponds to test the  hypothesis diff mu = 0.
#Formally the 0 is a plausible value (although at the very limit of the 95% HDI) 
az.summary(normal_trace, hdi_prob=0.95)



# Possible question 2: which is the posterior probability of a  positive effect?
#There is a  probability >95% of the effect being positive; thus we accept the hypothesis of a positive effect.
az.plot_posterior(normal_trace,  var_names="diff_of_means", ref_val=0, hdi_prob=0.95);


#Possible question #3
# Assuming the differences of +-1 are practically negligible, we define the rope as [-1, +1].
# Which is the probability of the effect being practically negligible or practically significant?
# The probability of rope is shown in figure, 
#we compute in the next slide  the probability of the positive effect being significant by working on the samples of the trace 
az.plot_posterior(normal_trace,  var_names="diff_of_means", rope=[-1,1]);


#Computing the probability of the positive effect being practically positive, practically negative or practically equivalent by working with the trace.
# This is a more detailed answer compared to the previous ones.
samples                  = az.extract(normal_trace)
diff_samples             = samples.diff_of_means.values
p_significant_positive   =  ( (diff_samples > 1).sum() ) / len(diff_samples)
p_significant_negative   = ( (diff_samples < -1).sum()) / len(diff_samples)
p_practically_eq         = 1-  p_significant_negative  -  p_significant_positive

print("p_significant_positive: ", "%.3f" % p_significant_positive)
print("p_practically_eq: ", "%.3f" % p_practically_eq)
print("p_significant_negative: ", "%.3f" % p_significant_negative)





# Quiz yourself: write a pseudo code explaining what the code below does.
with normal_model:
     ppc = pm.sample_posterior_predictive(normal_trace)
    
# The density is too low in the bulk of the distribution, for both groups. 
az.plot_ppc(ppc);





with pm.Model() as student_model:
    #prior are  unchanged.
    mu_drug_t         = pm.Normal    ('mu_drug_t',     mu = 100,  sigma = 5)
    mu_placebo_t      = pm.Normal    ('mu_placebo_t',   mu = 100,  sigma = 5)
    sigma_drug_t      = pm.HalfNormal ('sigma_drug_t',  sigma=25)
    sigma_placebo_t   = pm.HalfNormal ('sigma_placebo_t', sigma=25)

    #But now we adopt a robust likelihood. 
    #For simplicity we use a Student T with nu=4.  A more sophisticated approach would be to put a prior also on nu, but
    #that makes the model much more sensitive on the prior choice. 
    y_drug = pm.StudentT ('y_drug',       nu=4, mu=mu_drug_t, sigma=sigma_drug_t,       observed= iq_drug)
    y_placebo = pm.StudentT ('y_placebo', nu=4, mu=mu_placebo_t, sigma=sigma_placebo_t, observed= iq_placebo)
    
    #Derived quantities:
    diff_of_means_t = pm.Deterministic('diff_of_means', mu_drug_t - mu_placebo_t)
    student_trace    = pm.sample(return_inferencedata=True)


#the fit is better compare to the normal model, though not yet perfect for the placebo group.
with student_model:
    ppc_t = pm.sample_posterior_predictive(student_trace)
    az.plot_ppc(ppc_t);


# the sigma decreases by almost a half compared to the Gaussian model, as the student distribution filters outliers.
# as a results, the hdi become shorter, and the amount of difference between the two groups becomes clearer.
pd.concat( [az.summary(student_trace,  hdi_prob=0.95), az.summary(normal_trace, hdi_prob=0.95) ])





# with the robust likelihood, the 0 is no longer within the HDI; it is no longer a plausible value.
# This model rejects the hypothesis of the two populations having the same mean.

az.plot_posterior(student_trace, var_names=['diff_of_means'],  ref_val=0, linewidth=3, hdi_prob=0.95);


# Posterior probability of a  positive effect according to the robust model (increases wrt the Gaussian model).
az.plot_posterior(student_trace,  var_names="diff_of_means", ref_val=0, hdi_prob=0.95);


#Posterior probability of the positive effect being practically positive, practically negative or practically equivalent, 
#according to the robust model.

student_samples             = az.extract(student_trace)
diff_samples                = student_samples.diff_of_means.values
p_significant_positive      =  ( (diff_samples > 1).sum() ) / len(diff_samples)
p_significant_negative      = ( (diff_samples < -1).sum()) / len(diff_samples)
p_practically_eq            = 1-  p_significant_negative  -  p_significant_positive

print("p_significant_positive: ", "%.3f" % p_significant_positive)
print("p_practically_eq: ", "%.3f" % p_practically_eq)
print("p_significant_negative: ", "%.3f" % p_significant_negative)




















#computing the effect size as a deterministic variable within the student model.

with pm.Model() as student_model_effect:
    #prior are  unchanged.
    mu_drug_t           = pm.Normal     ('mu_drug_t',       mu = 100,  sigma = 5)
    mu_placebo_t        = pm.Normal     ('mu_placebo_t',    mu = 100,  sigma = 5)
    sigma_drug_t        = pm.HalfNormal ('sigma_drug_t',    sigma=25)
    sigma_placebo_t     = pm.HalfNormal ('sigma_placebo_t', sigma=25)

    y_drug = pm.StudentT ('y_drug',       nu=4, mu=mu_drug_t,  sigma=sigma_drug_t,       observed= iq_drug)
    y_placebo = pm.StudentT ('y_placebo', nu=4, mu=mu_placebo_t, sigma=sigma_placebo_t, observed= iq_placebo)
    
    #Effect size as a deterministic variable.
    effect_size         = pm.Deterministic('effect_size', (mu_drug_t - mu_placebo_t) / (  (sigma_drug_t**2 + sigma_placebo_t**2) /2 )**(1/2))
    student_trace_effect    = pm.sample(return_inferencedata=True)


#Posterior probability of the effect size being negative, or positive  (disaggregated as small, medium and large).
samples                  = az.extract_dataset(student_trace_effect)
effect_samples      = samples.effect_size.values

# count the samples in which the effect size negative
p_negative             = ( ( (effect_samples<0).sum() ) /  len (effect_samples) )

#a slightly more complex syntax is necessary to count the sample within a given range
p_small                   =  np.logical_and(effect_samples > 0,  effect_samples < 0.3)
p_small                   =  p_small.sum() / len (effect_samples) 

p_medium             =  np.logical_and(effect_samples > 0.3,  effect_samples < 0.8)
p_medium             =  p_medium.sum() / len (effect_samples) 

p_large                   = ( ( (effect_samples>0.8).sum() ) /  len (effect_samples) )

print("p_negative: ", "%.3f" % p_negative)
print("p_small: ", "%.3f" % p_small)
print("p_medium: ", "%.3f" % p_medium)
print("p_large: ", "%.3f" % p_large)

#check the computed probs sum up to 1
print ("sum: ", p_large + p_medium + p_small + p_negative)


# Analysis of the mortality using the beta-binomial model
# A Beta(5,100) has expected value 0.05, and most of its mass below 0.1. This represents  appropriately our prior information.

with pm.Model() as binomial_diff:
    theta_treatment = pm.Beta('theta_treatment', alpha=5, beta=100)
    theta_control   =  pm.Beta('theta_control', alpha=5, beta=100)
    
    #we need to write the model using the binomial likelihood
    dead_treatment = pm.Binomial ('dead_treatment ',  p=theta_treatment, observed=22, n=680)
    dead_control   = pm.Binomial ('dead_control ',       p=theta_control, observed=39, n=674)
    
    #Difference between the two mortality rates is a deterministic variable.
    diff_theta      = pm.Deterministic('diff_theta', theta_treatment - theta_control)
    binomial_trace  = pm.sample(return_inferencedata=True)


#The posterrio mean for the death rates are 0.034 for the control group and 0.056 for the treatment group. 
az.summary(binomial_trace)


# The HDI does not contain the 0; it rejects the hypothesis of the two groups having the same probability of death.

# We also accept the hypothesis of the treatment reducing the mortality rate, as there is probability > 95%
# of the  treatment reducing the mortality rate.
# A more detailed analysis could consider different intervals, and report the posterior probability of the treament being slightly / medium/ very effective. 
az.plot_posterior(binomial_trace, var_names='diff_theta', ref_val=0);




